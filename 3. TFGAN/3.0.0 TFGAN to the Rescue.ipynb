{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFGAN to the Rescue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [TFGAN?](#TFGAN?)\n",
    "    - [Advantages](#Advantages)\n",
    "    - [Caveats](#Caveats)\n",
    "- [Inside TFGAN](#Inside-TFGAN)\n",
    "- [Links](#Links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFGAN?\n",
    "\n",
    "TFGAN was developed by Google Brain (now Google AI) and released to the public on December 12, 2017 (see [blogpost [1\\]](#1)); authored by Joel Shor and Sergio Guadarrama, TFGAN is a lightweight library built on top of TensorFlow (currently available under `contrib`) offering a one-stop solution for (almost) all of your GANs' training and evaluation needs.\n",
    "\n",
    "The code, documentation, and examples can be found both on TensorFlow website and on GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages\n",
    "\n",
    "- \"Double networks training,\" TFGAN offers an API that wraps a series of lower-level operations together resolving the headaches usually associated with the intertwined training of two different networks.\n",
    "- Popular  ready to use losses and penalties. \n",
    "- Pre-built summaries for monitoring and evaluating.\n",
    "- Pre-built commonly used evaluators like `Inception Score` or `Frechet Distance`.\n",
    "- \"Bag o' tricks\" AKA hacks, tricks and \"best practices\" highlighted in various papers that aid with training stability and quality. \n",
    "- Examples of complete Architecture based on the most cutting-edge research.\n",
    "\n",
    "However, most importantly it offers `GANEstimator`, an API built upon TensorFlow own Estimator API that makes GANs' training a breeze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caveats\n",
    "\n",
    "It is not gold all that shines, while TFGAN is in our opinion the best way to build custom GANs, we feel that we should mention some of its drawbacks:\n",
    "\n",
    "- Contrib's woes: being part of `contrib` means that the library's API could change in a backward incompatible way while also having potentially more bugs (before TensorFlow 1.10 due to circa 4 lines of code trying to export a model built with `GANEstimator` for serving resulted in fatal crashes).\n",
    "- Building custom losses for TFGAN can be a pain due to the verbosity and \"low-levelness\" of the code that needs writing.\n",
    "- Due to the abstractions offered by a higher level API, especially when using `GANEstimator`, debugging or customizing the engine under the hood can sometimes be an annoying experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inside TFGAN\n",
    "\n",
    "By taking a look at the [project structure [2\\]](#2), we can discover its functionalities.\n",
    "TFGAN is composed of several parts which were design to exist independently. These include the following main pieces:\n",
    "- Core: provides the main infrastructure needed to train a GAN. Training occurs in four phases, and each phase can be completed by custom-code or by using a TFGAN library call. The \"Core\" functions can be found in the `namedtuples.py` and `train.py`.\n",
    "- `estimator`: Estimator-like API that manages all the session related complexity for the developer, versatile and easy to use, `GANEstimator` inherits all the pros and cons of its parent. If you want to use the Estimator API (and you probably should), this is the way to use it with GANs without going insane from training two models together.\n",
    "- `features`: TFGAN implements many common GAN operations and normalization techniques for you to use, such instance normalization and conditioning.\n",
    "- `losses`: Easily experiment with already-implemented and well-tested losses and penalties, such as the Wasserstein loss, gradient penalty, mutual information penalty.\n",
    "- `eval`: Use `Inception Score` or `Frechet Distance` with a pre-trained Inception network to evaluate your unconditional generative model. You can also use your pre-trained classifier for more specific performance numbers, or use other methods for evaluating conditional generative models.\n",
    "- Examples and tutorial: these are provided under [TensorFlow Research Models [3\\]](#3) and contains a plethora of information on how to use TFGAN to make GAN training easier, or use the more complicated examples to jumpstart your project. These include unconditional and conditional GANs, InfoGANs, adversarial losses on existing networks, and image-to-image translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links\n",
    "\n",
    "<a id=1>[1]</a>: https://ai.googleblog.com/2017/12/tfgan-lightweight-library-for.html\n",
    "\n",
    "<a id=2>[2]</a>: \n",
    "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/gan/python\n",
    "\n",
    "<a id=3>[3]</a>: https://github.com/tensorflow/models/tree/master/research/gan/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
