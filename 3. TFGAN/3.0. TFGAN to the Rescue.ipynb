{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "<a href='https://colab.research.google.com/github/zurutech/gans-from-theory-to-production/blob/master/3.%20TFGAN/3.0.%20TFGAN%20to%20the%20Rescue.ipynb'>\n",
    "        <img align=\"left\" src='https://cdn-images-1.medium.com/max/800/1*ZpNn76K98snC9vDiIJ6Ldw.jpeg'></img>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {},
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<br>\n",
    "<div class=\"toc\"><ul class=\"toc-item\">\n",
    "    <li><span><a href=\"#TFGAN?\" data-toc-modified-id=\"TFGAN?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>TFGAN?</a></span>\n",
    "        <ul class=\"toc-item\">\n",
    "            <li><span><a href=\"#Advantages\" data-toc-modified-id=\"Advantages-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Advantages</a></span></li>\n",
    "            <li><span><a href=\"#Caveats\" data-toc-modified-id=\"Caveats-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Caveats</a></span></li>\n",
    "         </ul>\n",
    "     </li>\n",
    "     <li><span><a href=\"#Inside-TFGAN\" data-toc-modified-id=\"Inside-TFGAN-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Inside TFGAN</a></span></li>\n",
    "     <li><span><a href=\"#GANModel-vs.-GANEstimator\" data-toc-modified-id=\"GANModel-vs.-GANEstimator-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>GANModel vs. GANEstimator</a></span></li>\n",
    "     <li><span><a href=\"#Links\" data-toc-modified-id=\"Links-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Links</a></span>\n",
    "     </li></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "\n",
    "## TFGAN?\n",
    "\n",
    "TFGAN was developed by Google Brain (now Google AI) and released to the public on December 12, 2017 (see [blog post [1\\]](#1)); authored by Joel Shor and Sergio Guadarrama, TFGAN is a lightweight library built on top of TensorFlow (currently available under `contrib`) offering a one-stop solution for (almost) all of your GANs' training and evaluation needs.\n",
    "\n",
    "The code, documentation, and examples can be found both on TensorFlow website and on GitHub.\n",
    "\n",
    "### Advantages\n",
    "\n",
    "- \"**Double networks training**,\" TFGAN offers an API that makes GANs easy to train, wrapping a series of lower-level operations.\n",
    "- Popular, **ready to use losses** and penalties. \n",
    "- **Pre-built summaries** for monitoring and evaluating.\n",
    "- **Pre-built** commonly used **evaluators** like `Inception Score` or `Fréchet Distance.`\n",
    "- \"**Bag o' tricks**\" (AKA hacks and \"best practices\") that aid with training stability and quality. \n",
    "- In-depth **examples** of complete architectures, based on the most cutting-edge research.\n",
    "- Supports defining **custom GANs** using `GANModel` objects.\n",
    "\n",
    "Moreover, it offers `GANEstimator`, an API built upon TensorFlow own **Estimator API** that makes GANs' training a breeze.\n",
    "\n",
    "### Caveats\n",
    "\n",
    "It is not gold all that shines. While TFGAN is in our opinion the best way to build custom GANs, we should mention some of its drawbacks:\n",
    "\n",
    "- Contrib's woes: being part of `contrib` means that the API could change in a backward incompatible way and leading some bugs. Furthermore, it is not currently available in Tensorflow 2.0.\n",
    "- Building custom losses for TFGAN can be a pain due to the verbosity and \"low-levelness\" of the code that needs writing.\n",
    "- Due to the higher level API, debugging or customizing the engine under the hood can sometimes be an annoying experience. That happens for example when using GANEstimator.\n",
    "\n",
    "## Inside TFGAN\n",
    "\n",
    "By taking a look at the [project structure [2\\]](#2), we can discover its functionalities.\n",
    "Several independent parts compose the TFGAN structure. These include the following main pieces:\n",
    "- *Core*: provides the core infrastructure needed to train a GAN. Training occurs in four phases. Each phase can be completed by custom-code or by using a TFGAN library call. The \"Core\" functions can be found in the `namedtuples.py` and `train.py`.\n",
    "- `estimator`: it is a versatile and easy to use Estimator-like API. It manages all the session related complexity for the developer. `GANEstimator` inherits from this class. The Estimator API allows you to train a GAN without the hassle of manage the adversarial training.\n",
    "- `features`: TFGAN implements many useful GAN operations and normalization techniques. Among these, there are instance normalization and conditioning.\n",
    "- `losses`: Include a set of already-implemented and well-tested losses and penalties — for example, the Wasserstein loss, gradient penalty, and mutual information penalty.\n",
    "- `eval`: Use `Inception Score` or `Fréchet Distance` with a pre-trained Inception network to evaluate your unconditional generative model. You can also use your pre-trained classifier. Also, you can use other methods for evaluating conditional generative models.\n",
    "- *Examples and tutorial*: [TensorFlow Research Models [3\\]](#3) provides many examples and tutorial. Moreover, it contains a plethora of information on how to use TFGAN to make GAN training easier. It also presents other more complicated examples. These include unconditional and conditional GANs, InfoGANs, adversarial losses on existing networks, and image-to-image translation.\n",
    "\n",
    "## GANModel vs. GANEstimator\n",
    "\n",
    "While we focus our attention on `GANEstimator`, the real raw power of TFGAN is its flexibility. This trait, offered by its lower level structures, enables the training of almost all kinds of GAN.\n",
    "\n",
    "> Training in TFGAN typically consists of the following steps:\n",
    "> 1. Specify the input to your networks.\n",
    "> 2. Set up your generator and discriminator using a `GANModel`.\n",
    "> 3. Specify your loss using a `GANLoss`.\n",
    "> 4. Create your train ops using a `GANTrainOps`.\n",
    "> 5. Run your train ops.\n",
    "\n",
    "For this workshop we decided to go with `GANEstimator` over `GANModel` for a couple of reason:\n",
    "\n",
    "- `Estimator API` is easier to learn, to use and is more suited for production deployment.\n",
    "- **DCGAN** (the GAN that powers up our demos) can be modeled and trained using `GANEstimator`.\n",
    "- Most of the TFGAN tutorials/examples focus on GANModel. For this reason, we wanted to increase the learning material covering `GANEstimator`.\n",
    "\n",
    "## Links\n",
    "\n",
    "<a id=\"1\">[1]</a>: https://ai.googleblog.com/2017/12/tfgan-lightweight-library-for.html\n",
    "\n",
    "<a id=\"2\">[2]</a>: \n",
    "https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/gan/python\n",
    "\n",
    "<a id=\"3\">[3]</a>: https://github.com/tensorflow/models/tree/master/research/gan/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": "goo#%% md\n<img src=\"../images/logo.jpg\" style=\"width:85px;height:85px;float:left\" /><h1 style=\"position:relative;float:left;display:inline\">TFGAN to the Rescue</h1>"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "210.833px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
