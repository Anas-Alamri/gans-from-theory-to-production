{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/logo.jpg\" style=\"width:85px;height:85px;float:left\" />\n",
    "<h1 style=\"position:relative;float:left;display:inline\">Writing a GAN using AshPy and TensorFlow Datasets</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "<a href='https://colab.research.google.com/github/zurutech/gans-from-theory-to-production/blob/master/3.%20AshPy/3.1.%20AshPy%20and%20TensorFlow%20Datasets.ipynb'>\n",
    "    <img align=\"left\" src='https://cdn-images-1.medium.com/max/800/1*ZpNn76K98snC9vDiIJ6Ldw.jpeg'></img>\n",
    "</a>\n",
    "-->\n",
    "<a href=\"http://mybinder.org/v2/gh/zurutech/gans-from-theory-to-production/master\">\n",
    "    <img align=\"left\" src=\"http://mybinder.org/badge_logo.svg\" />\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "! pip install --upgrade tensorflow-gpu==2.0.0beta1\n",
    "# ! pip install --upgrade tensorflow==2.0.0beta1\n",
    "! pip install --upgrade ashpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#GANs-with-AshPy-and-TensorFlow-Datasets-(tfds)\" data-toc-modified-id=\"GANs-with-AshPy-and-TensorFlow-Datasets-(tfds)-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>GANs with AshPy and TensorFlow Datasets (tfds)</a></span><ul class=\"toc-item\"><li><span><a href=\"#AshPy-Essentials\" data-toc-modified-id=\"AshPy-Essentials-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>AshPy Essentials</a></span></li><li><span><a href=\"#tfds-and-AshPy-input-format\" data-toc-modified-id=\"tfds-and-AshPy-input-format-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>tfds and AshPy input format</a></span><ul class=\"toc-item\"><li><span><a href=\"#Getting-the-data-ready-to-use\" data-toc-modified-id=\"Getting-the-data-ready-to-use-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Getting the data ready to use</a></span></li></ul></li></ul></li><li><span><a href=\"#DCGAN-Theory-and-Practice\" data-toc-modified-id=\"DCGAN-Theory-and-Practice-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>DCGAN Theory and Practice</a></span><ul class=\"toc-item\"><li><span><a href=\"#Generator:-from-noise-to-insight\" data-toc-modified-id=\"Generator:-from-noise-to-insight-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Generator: from noise to insight</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deconvolution\" data-toc-modified-id=\"Deconvolution-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Deconvolution</a></span></li><li><span><a href=\"#Batch-Normalization\" data-toc-modified-id=\"Batch-Normalization-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Batch Normalization</a></span></li></ul></li><li><span><a href=\"#Discriminator\" data-toc-modified-id=\"Discriminator-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Discriminator</a></span></li><li><span><a href=\"#Loss-function:-a-bridge-between-two-networks\" data-toc-modified-id=\"Loss-function:-a-bridge-between-two-networks-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Loss function: a bridge between two networks</a></span></li><li><span><a href=\"#Tensorboard\" data-toc-modified-id=\"Tensorboard-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Tensorboard</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Training</a></span></li></ul></li><li><span><a href=\"#Towards-Serving\" data-toc-modified-id=\"Towards-Serving-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Towards Serving</a></span></li><li><span><a href=\"#Links\" data-toc-modified-id=\"Links-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Links</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GANs with AshPy and TensorFlow Datasets (tfds)\n",
    "\n",
    "In this notebook, we are going to try to define a GAN and its input data pipeline using the AshPy and `tfds`. Our aim is to build a **face generator** where each image is a $64\\times64\\times3$ tensor.\n",
    "\n",
    "### AshPy Essentials\n",
    "\n",
    "AshPy is a TensorFlow 2.0 library for (**distributed**) training, evaluation, model selection, and fast prototyping. It is designed to ease the burden of setting up all the nuances of the architectures built to train complex custom deep learning models.\n",
    "\n",
    "The library has been designed following the TensorFlow 2.0 principles:\n",
    "\n",
    "- Ease of use.\n",
    "- Keras models centric.\n",
    "\n",
    "(Some of ) the features AshPy offers are:\n",
    "\n",
    "- You can distribute your model training using any `tf.distribute` distribution strategy without worrying about anything.\n",
    "- You can develop a state of the art model with high-level intuitive code.\n",
    "- It is fully compatible with the TensorFlow 2.0 ecosytem.\n",
    "- Custom losses and training behaviours are easy to implement by defining custom `ashpy.Executor`.\n",
    "- Fully compatibile with the Keras API specification and the `tf.keras` package.\n",
    "- AshPy correctly uses `tf.function` to accelerate the training loop for you.\n",
    "- Automatic Model selection and model saving-restore.\n",
    "- Automatic integration with TensorBoard.\n",
    "- Ready to use models and losses for fast prototyping.\n",
    "\n",
    "![bella](images/dataset-ashpy.png)\n",
    "\n",
    "**AshPy enforces a programming style.**\n",
    "\n",
    "Every trainer accepts a Keras model (or more than one, it depends on the training type), a dataset, the executor (loss computation behavior) and the hyperparameters and all of them must implement well-defined interfaces.\n",
    "\n",
    "In order to correctly separate the data input pipeline from the model, let's introduce `tensorflow-datasets` (`tfds`): the collection of datasets ready to use, all built upon the `tf.data.Dataset` API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tfds and AshPy input format\n",
    "\n",
    "The `tf.data` API has been designed to write complex input pipelines in a very simple manner. It uses the **named pattern idiom** (also called **method chaining**) and its methods are inspired to the functional programming languages that applies transformations to lists.\n",
    "\n",
    "The most imporant class is the `tf.data.Dataset` class that represents a sequence of elements: can apply transformation to this sequence of elements in order to create our dataset.\n",
    "\n",
    "Every `ashpy.Trainer` requires a `tf.data.Dataset` object to use.\n",
    "\n",
    "When using a `ashpy.AdversarialTrainer` that, as the name suggests, implements the adversarial training process, the `tf.data.Dataset` object should be in a well-known format.\n",
    "\n",
    "In particular, the dataset return type must always be in the format\n",
    "\n",
    "```python\n",
    "tuple(tuple(a,b), c)\n",
    "```\n",
    "\n",
    "where:\n",
    "\n",
    "- **a** is the input sample.\n",
    "- **b** is the label/condition (if any, otherwise fill it with 0).\n",
    "- **c** is the generator input, usually the __noise__.\n",
    "\n",
    "Using `tensorflow-datasets` we don't have to bother about the download, preprocess and iterator generator: for the most common dataset everything is ready to use.\n",
    "\n",
    "Downloading, having all the information, and a `tf.data.Dataset` object ready-to-use is just a single line.\n",
    "\n",
    "#### Getting the data ready to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image(shape=(218, 178, 3), dtype=tf.uint8)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import ashpy\n",
    "from IPython import display\n",
    "\n",
    "dataset_name = \"celeb_a\"\n",
    "if dataset_name not in tfds.list_builders():\n",
    "    raise ValueError(f\"Something wrong with tfds: missing {dataset_name}\")\n",
    "dataset, info = tfds.load(dataset_name,split=tfds.Split.ALL, with_info=True)\n",
    "print(info.features[\"image\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our goal is to generate $64\\times64$ images and training on batches, we can use method chaining on the returned `dataset` object to generate an optimized training input pipeline that fits all our needs.\n",
    "\n",
    "Moreover, we have to follow the AshPy convention and return the data in the correct format:\n",
    "```python\n",
    "tuple(tuple(a,b), c)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_resize(features):\n",
    "    image = tf.image.convert_image_dtype(features[\"image\"], dtype=tf.float32)\n",
    "    image = (image - 0.5) * 2\n",
    "    image = tf.image.resize(image, size=(64, 64))\n",
    "    features[\"image\"] = image\n",
    "    return features\n",
    "\n",
    "# Extract a subset of the dataset (to speedup the training)\n",
    "dataset = dataset.take(1000)\n",
    "dataset = dataset.map(convert_and_resize)\n",
    "# Now the dataset is a dataset of dictionaries\n",
    "# setting it to the ashpy format.\n",
    "\n",
    "latent_dimension = 100\n",
    "dataset = dataset.map(lambda row: (\n",
    "    (row[\"image\"], 0), \n",
    "    tf.random.normal(shape=(latent_dimension,))\n",
    "))\n",
    "\n",
    "# Batch\n",
    "batch_size = 32\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading, post-processing and create an optimized input pipeline is just these few lines above!\n",
    "\n",
    "Since we're working on images, we'll use an architecture created for this purpose: DCGAN <sup>[3](#3)</sup>.\n",
    "\n",
    "## DCGAN Theory and Practice\n",
    "\n",
    "![DCGAN](images/dcgan.png)\n",
    "\n",
    "If you take a look at [this impressive list of GANs [2\\]](#2), you would find out that **DCGAN**, the architecture of our choice, is a small drop in the ocean. While there may be sexier ones, very few offers the same level of clarity, performance and computational efficiency. For these reasons DCGAN is considered one of the cornerstones of this field.\n",
    "\n",
    "Alec Radford, Luke Metz and Soumith Chintala proposed the architecture in [their 2015 paper [3\\]](#3). The idea behind DCGAN is quite straightforward. Combining a set of architectural constraints with the power of CNN yielded a robust, stable and competitive model. Moreover, the architecture is simple: 4 deconvolutional layers for the `Generator` and 4 convolutional layers for the `Discriminator`. The constraints are the following:\n",
    "\n",
    "- All pooling layers are replaced with strided convolutions (discriminator) and fractionally-strided convolutions (generator).\n",
    "- Batch-normalization used in both networks.\n",
    "- Removal of the fully-connected layers (except for the discriminator output).\n",
    "- `ReLU` for all Generator layers except the output, which uses `tanh`.\n",
    "- `LeakyReLU` activation in the discriminator for all layers.\n",
    "\n",
    "Recently there have been some advancements in state of the art (e.g., Spectral Normalization). However, it is essential to have a firm understanding of the basic concepts. So, we leave you (an opinionated) list of further resources at the end of this notebook, to get you up to speed with the most exciting researches.\n",
    "\n",
    "### Generator: from noise to insight\n",
    "\n",
    "![DCGAN Generator](images/dcgan_generator.png)\n",
    "\n",
    "Recalling the theoretical explanation, the Generator is the network responsible for the data-generation. It learns how to fool the discriminator, so it learns how to produce realistic results. Those results are then \"sampled\" from the learned manifold.\n",
    "\n",
    "The most common type of generator input is noise (i.e.: random values). More specialized GANs may require extra parameters. Since our full-demo uses a Deep Convolutional GAN (DCGAN), we don't need any other parameters.\n",
    "\n",
    "#### Deconvolution\n",
    "\n",
    "Intuitively, the idea behind this operation is the following:\n",
    "\n",
    "![Deconvolution](images/deconvolution.png)\n",
    "\n",
    "\n",
    "> When neural networks generate images, they build the images starting from low-resolution high-level descriptions. In this way, the network starts describing a \n",
    "> rough representation and then fill in the details to create the final image.\n",
    ">\n",
    ">To do this, we need some way to go from a lower resolution image to a higher one. We generally do this with the deconvolution operation. \n",
    ">Roughly, deconvolution layers allow the model to use the points from the small image to “paint” a larger area in the bigger output image.\n",
    "\n",
    "In practice, the deconvolution operation is often implemented by resizing, using bi-linear or nearest neighbor interpolation, followed by a convolution operation.\n",
    "\n",
    "#### Batch Normalization\n",
    "\n",
    "What you need to know about batch normalization is that is a layer that normalizes the values. TensorFlow makes it very easy to implement such operation:  \n",
    "\n",
    "```python\n",
    "tf.keras.layers.BatchNormalization()\n",
    "```\n",
    "\n",
    "The benefit of using batch normalization has been extensively discussed and proved in various papers. We do not enter into the theoretical depth of BatchNormalization, but you can refer to [[3\\]](#3), [[8\\]](#8) and [[9\\]](#9) to learn more about the topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1024*4*4, use_bias=False, input_shape=(100,)),\n",
    "    tf.keras.layers.Reshape((4,4,1024)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "    tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "    tf.keras.layers.Activation(tf.math.tanh)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "![DCGAN Discriminator](images/dcgan_discriminator.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "\n",
    "    tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.LeakyReLU(),\n",
    "    \n",
    "    tf.keras.layers.Reshape((-1,)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function: a bridge between two networks\n",
    "\n",
    "There are a lot of loss functions usable in GANs' architectures. From very domain-specific ones to others that are perfect for general use cases. Since our goal here falls in the latter category, we use the so-called **Non-Saturating Loss** which is the non-saturating variant of the **MinMax Loss** proposed by Goodfellow in the [original paper [1\\]](#1).\n",
    "\n",
    "As stated above, one of `AshPy`'s beauties is its offer of ready-to-use losses. If you cannot find the loss you want, you can create your own. \n",
    "\n",
    "We use the following two losses:\n",
    "\n",
    "```python\n",
    "from ashpy.losses.gan import DiscriminatorMinMax, GeneratorBCE\n",
    "generator_bce = GeneratorBCE()\n",
    "minmax = DiscriminatorMinMax()\n",
    "```\n",
    "\n",
    "It is that easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ashpy.losses.gan import DiscriminatorMinMax, GeneratorBCE\n",
    "generator_bce = GeneratorBCE()\n",
    "minmax = DiscriminatorMinMax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f67b80b5a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension and run it\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Using AshPy the training loop is already implemented and everyting is ready to be used in distributed or local fashion, witout any change.\n",
    "\n",
    "Just define the hyperparameters, like the optimizers to use, the metrics to measure, and the number of epochs to train, and the trainer object will do everything for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing checkpoint.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0819 12:21:36.018539 140086811756160 deprecation.py:323] From /data/pgaleone/env/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:182: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10] g_loss: 3.1023786067962646 - d_loss: 0.12607771158218384\n",
      "[20] g_loss: 3.9864680767059326 - d_loss: 0.20067942142486572\n",
      "[30] g_loss: 3.4156322479248047 - d_loss: 0.20362694561481476\n",
      "[31] Saved checkpoint: log/ckpts/ckpt-1\n",
      "Epoch 1 completed.\n",
      "[40] g_loss: 3.738818645477295 - d_loss: 0.020717082545161247\n",
      "[50] g_loss: 6.410630226135254 - d_loss: 0.01588129810988903\n",
      "[60] g_loss: 5.2700629234313965 - d_loss: 0.03122032806277275\n",
      "[62] Saved checkpoint: log/ckpts/ckpt-2\n",
      "Epoch 2 completed.\n",
      "[70] g_loss: 4.521557331085205 - d_loss: 0.05670560151338577\n",
      "[80] g_loss: 4.899657249450684 - d_loss: 0.03549738973379135\n",
      "[90] g_loss: 6.799798965454102 - d_loss: 0.07048636674880981\n",
      "[93] Saved checkpoint: log/ckpts/ckpt-3\n",
      "Epoch 3 completed.\n",
      "[100] g_loss: 4.4114227294921875 - d_loss: 0.010578876361250877\n",
      "[110] g_loss: 4.8765339851379395 - d_loss: 0.011637222021818161\n",
      "[120] g_loss: 5.257278919219971 - d_loss: 0.009329179301857948\n",
      "[124] Saved checkpoint: log/ckpts/ckpt-4\n",
      "Epoch 4 completed.\n",
      "[130] g_loss: 4.9585771560668945 - d_loss: 0.023170702159404755\n",
      "[140] g_loss: 5.894205093383789 - d_loss: 0.012838564813137054\n",
      "[150] g_loss: 4.928200721740723 - d_loss: 0.009139948524534702\n",
      "[155] Saved checkpoint: log/ckpts/ckpt-5\n",
      "Epoch 5 completed.\n",
      "[160] g_loss: 5.6016364097595215 - d_loss: 0.017319682985544205\n",
      "[170] g_loss: 5.878534317016602 - d_loss: 0.013493435457348824\n",
      "[180] g_loss: 5.244996547698975 - d_loss: 0.018036894500255585\n",
      "[186] Saved checkpoint: log/ckpts/ckpt-6\n",
      "Epoch 6 completed.\n",
      "[190] g_loss: 5.148247718811035 - d_loss: 0.009317823685705662\n",
      "[200] g_loss: 5.457226276397705 - d_loss: 0.019200630486011505\n",
      "[210] g_loss: 6.059512615203857 - d_loss: 0.010711759328842163\n",
      "[217] Saved checkpoint: log/ckpts/ckpt-7\n",
      "Epoch 7 completed.\n",
      "[220] g_loss: 6.370789527893066 - d_loss: 0.0070939213037490845\n",
      "[230] g_loss: 6.241079807281494 - d_loss: 0.008160337805747986\n",
      "[240] g_loss: 6.505731582641602 - d_loss: 0.0035418393090367317\n",
      "[248] Saved checkpoint: log/ckpts/ckpt-8\n",
      "Epoch 8 completed.\n",
      "[250] g_loss: 5.684237480163574 - d_loss: 0.00874158926308155\n",
      "[260] g_loss: 5.956435203552246 - d_loss: 0.004300081171095371\n",
      "[270] g_loss: 4.845244407653809 - d_loss: 0.009326674044132233\n",
      "[279] Saved checkpoint: log/ckpts/ckpt-9\n",
      "Epoch 9 completed.\n",
      "[280] g_loss: 5.183292865753174 - d_loss: 0.02256593480706215\n",
      "[290] g_loss: 6.15994930267334 - d_loss: 0.0048830099403858185\n",
      "[300] g_loss: 5.448650360107422 - d_loss: 0.009873881004750729\n",
      "[310] g_loss: 5.517974376678467 - d_loss: 0.0181583259254694\n",
      "[310] Saved checkpoint: log/ckpts/ckpt-10\n",
      "Epoch 10 completed.\n",
      "[320] g_loss: 5.769454002380371 - d_loss: 0.0032928846776485443\n",
      "[330] g_loss: 5.88133430480957 - d_loss: 0.009940098971128464\n",
      "[340] g_loss: 7.582242012023926 - d_loss: 0.014604390598833561\n",
      "[341] Saved checkpoint: log/ckpts/ckpt-11\n",
      "Epoch 11 completed.\n",
      "[350] g_loss: 7.133856773376465 - d_loss: 0.0016807098872959614\n",
      "[360] g_loss: 5.1846513748168945 - d_loss: 0.0075088911689817905\n",
      "[370] g_loss: 22.239587783813477 - d_loss: 0.06980240345001221\n",
      "[372] Saved checkpoint: log/ckpts/ckpt-12\n",
      "Epoch 12 completed.\n",
      "[380] g_loss: 11.25786018371582 - d_loss: 0.0011004871921613812\n",
      "[390] g_loss: 7.882415771484375 - d_loss: 0.07874580472707748\n",
      "[400] g_loss: 6.761579990386963 - d_loss: 0.46495023369789124\n",
      "[403] Saved checkpoint: log/ckpts/ckpt-13\n",
      "Epoch 13 completed.\n",
      "[410] g_loss: 12.065652847290039 - d_loss: 0.004545906558632851\n",
      "[420] g_loss: 10.570940017700195 - d_loss: 0.08420277386903763\n",
      "[430] g_loss: 8.351533889770508 - d_loss: 0.018142888322472572\n",
      "[434] Saved checkpoint: log/ckpts/ckpt-14\n",
      "Epoch 14 completed.\n",
      "[440] g_loss: 5.870092391967773 - d_loss: 0.00799465924501419\n",
      "[450] g_loss: 5.665740966796875 - d_loss: 0.020035244524478912\n",
      "[460] g_loss: 8.786937713623047 - d_loss: 0.0011177377309650183\n",
      "[465] Saved checkpoint: log/ckpts/ckpt-15\n",
      "Epoch 15 completed.\n",
      "[470] g_loss: 5.935380458831787 - d_loss: 0.18925610184669495\n",
      "[480] g_loss: 9.667341232299805 - d_loss: 0.016973204910755157\n",
      "[490] g_loss: 9.21867561340332 - d_loss: 0.007320918142795563\n",
      "[496] Saved checkpoint: log/ckpts/ckpt-16\n",
      "Epoch 16 completed.\n",
      "[500] g_loss: 4.7344160079956055 - d_loss: 0.014386778697371483\n",
      "[510] g_loss: 13.541781425476074 - d_loss: 0.002624626737087965\n",
      "[520] g_loss: 9.897106170654297 - d_loss: 0.05299905315041542\n",
      "[527] Saved checkpoint: log/ckpts/ckpt-17\n",
      "Epoch 17 completed.\n",
      "[530] g_loss: 7.879406929016113 - d_loss: 0.1751689612865448\n",
      "[540] g_loss: 8.024713516235352 - d_loss: 0.04309523478150368\n",
      "[550] g_loss: 4.440500736236572 - d_loss: 0.32216888666152954\n",
      "[558] Saved checkpoint: log/ckpts/ckpt-18\n",
      "Epoch 18 completed.\n",
      "[560] g_loss: 7.158935546875 - d_loss: 0.025101879611611366\n",
      "[570] g_loss: 5.371479034423828 - d_loss: 0.02192622981965542\n",
      "[580] g_loss: 5.064209938049316 - d_loss: 0.01668645069003105\n",
      "[589] Saved checkpoint: log/ckpts/ckpt-19\n",
      "Epoch 19 completed.\n",
      "[590] g_loss: 2.859241247177124 - d_loss: 0.07393534481525421\n",
      "[600] g_loss: 7.663154602050781 - d_loss: 0.0643743947148323\n",
      "[610] g_loss: 7.181273937225342 - d_loss: 0.005763594061136246\n",
      "[620] g_loss: 8.900083541870117 - d_loss: 0.01588249020278454\n",
      "[620] Saved checkpoint: log/ckpts/ckpt-20\n",
      "Epoch 20 completed.\n",
      "[630] g_loss: 5.296753883361816 - d_loss: 0.012030952610075474\n",
      "[640] g_loss: 5.886201858520508 - d_loss: 0.00916209165006876\n",
      "[650] g_loss: 6.044140815734863 - d_loss: 0.1324215680360794\n",
      "[651] Saved checkpoint: log/ckpts/ckpt-21\n",
      "Epoch 21 completed.\n",
      "[660] g_loss: 3.9311914443969727 - d_loss: 0.019069254398345947\n",
      "[670] g_loss: 4.757063865661621 - d_loss: 0.04260611534118652\n",
      "[680] g_loss: 5.824698448181152 - d_loss: 0.019392358139157295\n",
      "[682] Saved checkpoint: log/ckpts/ckpt-22\n",
      "Epoch 22 completed.\n",
      "[690] g_loss: 6.651150226593018 - d_loss: 0.12095968425273895\n",
      "[700] g_loss: 5.763812065124512 - d_loss: 0.013273151591420174\n",
      "[710] g_loss: 6.145668983459473 - d_loss: 0.023223184049129486\n",
      "[713] Saved checkpoint: log/ckpts/ckpt-23\n",
      "Epoch 23 completed.\n",
      "[720] g_loss: 6.137603759765625 - d_loss: 0.01074201986193657\n",
      "[730] g_loss: 7.1913347244262695 - d_loss: 0.042663414031267166\n",
      "[740] g_loss: 6.4861321449279785 - d_loss: 0.0306495763361454\n",
      "[744] Saved checkpoint: log/ckpts/ckpt-24\n",
      "Epoch 24 completed.\n",
      "[750] g_loss: 4.079070091247559 - d_loss: 0.044894568622112274\n",
      "[760] g_loss: 12.057268142700195 - d_loss: 0.0791081041097641\n",
      "[770] g_loss: 10.427400588989258 - d_loss: 0.05637315660715103\n",
      "[775] Saved checkpoint: log/ckpts/ckpt-25\n",
      "Epoch 25 completed.\n",
      "[780] g_loss: 7.273400783538818 - d_loss: 0.015152228996157646\n",
      "[790] g_loss: 4.394523620605469 - d_loss: 0.07694245874881744\n",
      "[800] g_loss: 5.961411476135254 - d_loss: 0.04551674425601959\n",
      "[806] Saved checkpoint: log/ckpts/ckpt-26\n",
      "Epoch 26 completed.\n",
      "[810] g_loss: 6.513354301452637 - d_loss: 0.12701451778411865\n",
      "[820] g_loss: 8.435441017150879 - d_loss: 0.032405346632003784\n",
      "[830] g_loss: 6.2591328620910645 - d_loss: 0.01592777483165264\n",
      "[837] Saved checkpoint: log/ckpts/ckpt-27\n",
      "Epoch 27 completed.\n",
      "[840] g_loss: 4.202647686004639 - d_loss: 0.030437519773840904\n",
      "[850] g_loss: 5.082765579223633 - d_loss: 0.009519916027784348\n",
      "[860] g_loss: 4.136125564575195 - d_loss: 0.020178986713290215\n",
      "[868] Saved checkpoint: log/ckpts/ckpt-28\n",
      "Epoch 28 completed.\n",
      "[870] g_loss: 4.217525005340576 - d_loss: 0.038146425038576126\n",
      "[880] g_loss: 5.428022384643555 - d_loss: 0.0075008440762758255\n",
      "[890] g_loss: 3.2017860412597656 - d_loss: 0.04609150066971779\n",
      "[899] Saved checkpoint: log/ckpts/ckpt-29\n",
      "Epoch 29 completed.\n",
      "[900] g_loss: 5.9564313888549805 - d_loss: 0.07665707916021347\n",
      "[910] g_loss: 5.793330192565918 - d_loss: 0.05008881911635399\n",
      "[920] g_loss: 4.26793098449707 - d_loss: 0.022030409425497055\n",
      "[930] g_loss: 6.199880123138428 - d_loss: 0.0073050884529948235\n",
      "[930] Saved checkpoint: log/ckpts/ckpt-30\n",
      "Epoch 30 completed.\n",
      "[940] g_loss: 6.266993522644043 - d_loss: 0.006497543305158615\n",
      "[950] g_loss: 8.255200386047363 - d_loss: 0.02907034382224083\n",
      "[960] g_loss: 8.434989929199219 - d_loss: 0.02551720291376114\n",
      "[961] Saved checkpoint: log/ckpts/ckpt-31\n",
      "Epoch 31 completed.\n",
      "[970] g_loss: 5.102595329284668 - d_loss: 0.011980293318629265\n",
      "[980] g_loss: 5.223048210144043 - d_loss: 0.007760209497064352\n",
      "[990] g_loss: 2.9370062351226807 - d_loss: 0.04330412298440933\n",
      "[992] Saved checkpoint: log/ckpts/ckpt-32\n",
      "Epoch 32 completed.\n",
      "[1000] g_loss: 7.4735188484191895 - d_loss: 0.014427844434976578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1010] g_loss: 6.359277725219727 - d_loss: 0.0076248059049248695\n",
      "[1020] g_loss: 5.024300575256348 - d_loss: 0.01778220571577549\n",
      "[1023] Saved checkpoint: log/ckpts/ckpt-33\n",
      "Epoch 33 completed.\n",
      "[1030] g_loss: 4.124502182006836 - d_loss: 0.022080373018980026\n",
      "[1040] g_loss: 5.012825012207031 - d_loss: 0.14577282965183258\n",
      "[1050] g_loss: 11.733231544494629 - d_loss: 0.03863545507192612\n",
      "[1054] Saved checkpoint: log/ckpts/ckpt-34\n",
      "Epoch 34 completed.\n",
      "[1060] g_loss: 6.682621002197266 - d_loss: 0.04453770071268082\n",
      "[1070] g_loss: 5.718838691711426 - d_loss: 0.03886964172124863\n",
      "[1080] g_loss: 5.7575459480285645 - d_loss: 0.02707757242023945\n",
      "[1085] Saved checkpoint: log/ckpts/ckpt-35\n",
      "Epoch 35 completed.\n",
      "[1090] g_loss: 2.5985889434814453 - d_loss: 0.16201108694076538\n",
      "[1100] g_loss: 17.208778381347656 - d_loss: 0.013130931183695793\n",
      "[1110] g_loss: 5.5402116775512695 - d_loss: 0.09380918741226196\n",
      "[1116] Saved checkpoint: log/ckpts/ckpt-36\n",
      "Epoch 36 completed.\n",
      "[1120] g_loss: 3.9489543437957764 - d_loss: 0.07270200550556183\n",
      "[1130] g_loss: 5.666616439819336 - d_loss: 0.020022651180624962\n",
      "[1140] g_loss: 5.962166786193848 - d_loss: 0.012481482699513435\n",
      "[1147] Saved checkpoint: log/ckpts/ckpt-37\n",
      "Epoch 37 completed.\n",
      "[1150] g_loss: 5.8916192054748535 - d_loss: 0.0856066569685936\n",
      "[1160] g_loss: 4.729010581970215 - d_loss: 0.02341926097869873\n",
      "[1170] g_loss: 5.475615501403809 - d_loss: 0.08206634223461151\n",
      "[1178] Saved checkpoint: log/ckpts/ckpt-38\n",
      "Epoch 38 completed.\n",
      "[1180] g_loss: 4.708756446838379 - d_loss: 0.058550238609313965\n",
      "[1190] g_loss: 6.041031360626221 - d_loss: 0.027216961607336998\n",
      "[1200] g_loss: 5.5421528816223145 - d_loss: 0.025448864325881004\n",
      "[1209] Saved checkpoint: log/ckpts/ckpt-39\n",
      "Epoch 39 completed.\n",
      "[1210] g_loss: 5.493332862854004 - d_loss: 0.03377596288919449\n",
      "[1220] g_loss: 6.455388069152832 - d_loss: 0.12003148347139359\n",
      "[1230] g_loss: 7.225396156311035 - d_loss: 0.03320356458425522\n",
      "[1240] g_loss: 5.873680114746094 - d_loss: 0.03195897489786148\n",
      "[1240] Saved checkpoint: log/ckpts/ckpt-40\n",
      "Epoch 40 completed.\n",
      "[1250] g_loss: 5.026466369628906 - d_loss: 0.12036731094121933\n",
      "[1260] g_loss: 8.719188690185547 - d_loss: 0.003345474833622575\n",
      "[1270] g_loss: 8.590145111083984 - d_loss: 0.09620846807956696\n",
      "[1271] Saved checkpoint: log/ckpts/ckpt-41\n",
      "Epoch 41 completed.\n",
      "[1280] g_loss: 10.748300552368164 - d_loss: 0.018843695521354675\n",
      "[1290] g_loss: 6.900373935699463 - d_loss: 0.012242394499480724\n",
      "[1300] g_loss: 4.36337947845459 - d_loss: 0.02378802001476288\n",
      "[1302] Saved checkpoint: log/ckpts/ckpt-42\n",
      "Epoch 42 completed.\n",
      "[1310] g_loss: 3.931943416595459 - d_loss: 0.08799020946025848\n",
      "[1320] g_loss: 10.910233497619629 - d_loss: 0.0026968196034431458\n",
      "[1330] g_loss: 13.40604019165039 - d_loss: 0.007808824069797993\n",
      "[1333] Saved checkpoint: log/ckpts/ckpt-43\n",
      "Epoch 43 completed.\n",
      "[1340] g_loss: 12.369461059570312 - d_loss: 0.05323459953069687\n",
      "[1350] g_loss: 5.585690498352051 - d_loss: 0.02562014013528824\n",
      "[1360] g_loss: 3.8004708290100098 - d_loss: 0.13114945590496063\n",
      "[1364] Saved checkpoint: log/ckpts/ckpt-44\n",
      "Epoch 44 completed.\n",
      "[1370] g_loss: 6.47030782699585 - d_loss: 0.03328824043273926\n",
      "[1380] g_loss: 5.819481372833252 - d_loss: 0.03815832361578941\n",
      "[1390] g_loss: 7.340326309204102 - d_loss: 0.06092369556427002\n",
      "[1395] Saved checkpoint: log/ckpts/ckpt-45\n",
      "Epoch 45 completed.\n",
      "[1400] g_loss: 7.4056925773620605 - d_loss: 0.014194740913808346\n",
      "[1410] g_loss: 4.132082939147949 - d_loss: 0.05728263035416603\n",
      "[1420] g_loss: 4.378083229064941 - d_loss: 0.061040475964546204\n",
      "[1426] Saved checkpoint: log/ckpts/ckpt-46\n",
      "Epoch 46 completed.\n",
      "[1430] g_loss: 5.439396858215332 - d_loss: 0.014740421436727047\n",
      "[1440] g_loss: 4.645868301391602 - d_loss: 0.03982992097735405\n",
      "[1450] g_loss: 7.2722978591918945 - d_loss: 0.038653161376714706\n",
      "[1457] Saved checkpoint: log/ckpts/ckpt-47\n",
      "Epoch 47 completed.\n",
      "[1460] g_loss: 5.279430866241455 - d_loss: 0.07464281469583511\n",
      "[1470] g_loss: 5.992912292480469 - d_loss: 0.009952131658792496\n",
      "[1480] g_loss: 8.047004699707031 - d_loss: 0.002989282365888357\n",
      "[1488] Saved checkpoint: log/ckpts/ckpt-48\n",
      "Epoch 48 completed.\n",
      "[1490] g_loss: 7.147835731506348 - d_loss: 0.008346072398126125\n",
      "[1500] g_loss: 7.784071922302246 - d_loss: 0.042267583310604095\n",
      "[1510] g_loss: 7.501889228820801 - d_loss: 0.008963889442384243\n",
      "[1519] Saved checkpoint: log/ckpts/ckpt-49\n",
      "Epoch 49 completed.\n",
      "[1520] g_loss: 8.146015167236328 - d_loss: 0.13922521471977234\n",
      "[1530] g_loss: 8.667744636535645 - d_loss: 0.04902186244726181\n",
      "[1540] g_loss: 6.1707763671875 - d_loss: 0.011754181236028671\n",
      "[1550] g_loss: 11.011358261108398 - d_loss: 0.010825403034687042\n",
      "[1550] Saved checkpoint: log/ckpts/ckpt-50\n",
      "Epoch 50 completed.\n",
      "[1560] g_loss: 5.417942047119141 - d_loss: 0.04043992981314659\n",
      "[1570] g_loss: 5.713396072387695 - d_loss: 0.031206734478473663\n",
      "[1580] g_loss: 6.901727199554443 - d_loss: 0.0054505737498402596\n",
      "[1581] Saved checkpoint: log/ckpts/ckpt-51\n",
      "Epoch 51 completed.\n",
      "[1590] g_loss: 7.789931774139404 - d_loss: 0.055582672357559204\n",
      "[1600] g_loss: 9.86368179321289 - d_loss: 0.003954363986849785\n",
      "[1610] g_loss: 7.882382392883301 - d_loss: 0.016402987763285637\n",
      "[1612] Saved checkpoint: log/ckpts/ckpt-52\n",
      "Epoch 52 completed.\n",
      "[1620] g_loss: 7.895876407623291 - d_loss: 0.007650597952306271\n",
      "[1630] g_loss: 6.189798355102539 - d_loss: 0.028143413364887238\n",
      "[1640] g_loss: 6.754125118255615 - d_loss: 0.027281634509563446\n",
      "[1643] Saved checkpoint: log/ckpts/ckpt-53\n",
      "Epoch 53 completed.\n",
      "[1650] g_loss: 7.155125617980957 - d_loss: 0.06734560430049896\n",
      "[1660] g_loss: 4.203664779663086 - d_loss: 0.05122646689414978\n",
      "[1670] g_loss: 2.7244374752044678 - d_loss: 0.12167788296937943\n",
      "[1674] Saved checkpoint: log/ckpts/ckpt-54\n",
      "Epoch 54 completed.\n",
      "[1680] g_loss: 5.139671325683594 - d_loss: 0.05100259557366371\n",
      "[1690] g_loss: 4.923069000244141 - d_loss: 0.04365231841802597\n",
      "[1700] g_loss: 5.969575881958008 - d_loss: 0.03734192997217178\n",
      "[1705] Saved checkpoint: log/ckpts/ckpt-55\n",
      "Epoch 55 completed.\n",
      "[1710] g_loss: 8.553760528564453 - d_loss: 0.016416920349001884\n",
      "[1720] g_loss: 5.638792037963867 - d_loss: 0.03386463224887848\n",
      "[1730] g_loss: 6.04780912399292 - d_loss: 0.0541812926530838\n",
      "[1736] Saved checkpoint: log/ckpts/ckpt-56\n",
      "Epoch 56 completed.\n",
      "[1740] g_loss: 2.9533073902130127 - d_loss: 0.11653855443000793\n",
      "[1750] g_loss: 4.113640785217285 - d_loss: 0.057335663586854935\n",
      "[1760] g_loss: 5.860651969909668 - d_loss: 0.1100083440542221\n",
      "[1767] Saved checkpoint: log/ckpts/ckpt-57\n",
      "Epoch 57 completed.\n",
      "[1770] g_loss: 4.914380073547363 - d_loss: 0.07978592813014984\n",
      "[1780] g_loss: 5.211361408233643 - d_loss: 0.04015737771987915\n",
      "[1790] g_loss: 8.598270416259766 - d_loss: 0.07702033221721649\n",
      "[1798] Saved checkpoint: log/ckpts/ckpt-58\n",
      "Epoch 58 completed.\n",
      "[1800] g_loss: 6.121094703674316 - d_loss: 0.00728960707783699\n",
      "[1810] g_loss: 4.858556747436523 - d_loss: 0.025246012955904007\n",
      "[1820] g_loss: 5.958443641662598 - d_loss: 0.019047453999519348\n",
      "[1829] Saved checkpoint: log/ckpts/ckpt-59\n",
      "Epoch 59 completed.\n",
      "[1830] g_loss: 4.9569854736328125 - d_loss: 0.06634870171546936\n",
      "[1840] g_loss: 6.371569633483887 - d_loss: 0.013746453449130058\n",
      "[1850] g_loss: 6.148028373718262 - d_loss: 0.017733534798026085\n",
      "[1860] g_loss: 3.3669960498809814 - d_loss: 0.07963071763515472\n",
      "[1860] Saved checkpoint: log/ckpts/ckpt-60\n",
      "Epoch 60 completed.\n",
      "[1870] g_loss: 7.723595142364502 - d_loss: 0.07075580954551697\n",
      "[1880] g_loss: 8.432710647583008 - d_loss: 0.007862662896513939\n",
      "[1890] g_loss: 7.281761169433594 - d_loss: 0.034189462661743164\n",
      "[1891] Saved checkpoint: log/ckpts/ckpt-61\n",
      "Epoch 61 completed.\n",
      "[1900] g_loss: 6.992920398712158 - d_loss: 0.045636579394340515\n",
      "[1910] g_loss: 8.45610523223877 - d_loss: 0.017208265140652657\n",
      "[1920] g_loss: 5.995095729827881 - d_loss: 0.06678882986307144\n",
      "[1922] Saved checkpoint: log/ckpts/ckpt-62\n",
      "Epoch 62 completed.\n",
      "[1930] g_loss: 5.701760768890381 - d_loss: 0.014446316286921501\n",
      "[1940] g_loss: 6.626168251037598 - d_loss: 0.0726042091846466\n",
      "[1950] g_loss: 4.634227752685547 - d_loss: 0.10326048731803894\n",
      "[1953] Saved checkpoint: log/ckpts/ckpt-63\n",
      "Epoch 63 completed.\n",
      "[1960] g_loss: 7.550168037414551 - d_loss: 0.09261584281921387\n",
      "[1970] g_loss: 6.252792835235596 - d_loss: 0.08308938145637512\n",
      "[1980] g_loss: 4.1666483879089355 - d_loss: 0.17290033400058746\n",
      "[1984] Saved checkpoint: log/ckpts/ckpt-64\n",
      "Epoch 64 completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1990] g_loss: 7.722517013549805 - d_loss: 0.00799054466187954\n",
      "[2000] g_loss: 5.72402286529541 - d_loss: 0.03791375085711479\n",
      "[2010] g_loss: 7.289953231811523 - d_loss: 0.004798362031579018\n",
      "[2015] Saved checkpoint: log/ckpts/ckpt-65\n",
      "Epoch 65 completed.\n",
      "[2020] g_loss: 8.256820678710938 - d_loss: 0.030118905007839203\n",
      "[2030] g_loss: 3.9956235885620117 - d_loss: 0.048132672905921936\n",
      "[2040] g_loss: 4.1065239906311035 - d_loss: 0.04828700050711632\n",
      "[2046] Saved checkpoint: log/ckpts/ckpt-66\n",
      "Epoch 66 completed.\n",
      "[2050] g_loss: 3.3962221145629883 - d_loss: 0.06908851861953735\n",
      "[2060] g_loss: 5.553679466247559 - d_loss: 0.024330569431185722\n",
      "[2070] g_loss: 5.311236381530762 - d_loss: 0.019621383398771286\n",
      "[2077] Saved checkpoint: log/ckpts/ckpt-67\n",
      "Epoch 67 completed.\n",
      "[2080] g_loss: 8.156453132629395 - d_loss: 0.041080404072999954\n",
      "[2090] g_loss: 5.171710014343262 - d_loss: 0.01762758567929268\n",
      "[2100] g_loss: 5.794774532318115 - d_loss: 0.051343221217393875\n",
      "[2108] Saved checkpoint: log/ckpts/ckpt-68\n",
      "Epoch 68 completed.\n",
      "[2110] g_loss: 4.549224853515625 - d_loss: 0.03712745010852814\n",
      "[2120] g_loss: 5.345789909362793 - d_loss: 0.017411397770047188\n",
      "[2130] g_loss: 4.812196254730225 - d_loss: 0.05315807834267616\n",
      "[2139] Saved checkpoint: log/ckpts/ckpt-69\n",
      "Epoch 69 completed.\n",
      "[2140] g_loss: 3.4364800453186035 - d_loss: 0.04408092796802521\n",
      "[2150] g_loss: 8.108037948608398 - d_loss: 0.021984228864312172\n",
      "[2160] g_loss: 6.136562347412109 - d_loss: 0.015000386163592339\n",
      "[2170] g_loss: 6.824863910675049 - d_loss: 0.02800039015710354\n",
      "[2170] Saved checkpoint: log/ckpts/ckpt-70\n",
      "Epoch 70 completed.\n",
      "[2180] g_loss: 6.9577107429504395 - d_loss: 0.050698429346084595\n",
      "[2190] g_loss: 8.303876876831055 - d_loss: 0.004667152650654316\n",
      "[2200] g_loss: 10.018818855285645 - d_loss: 0.019483156502246857\n",
      "[2201] Saved checkpoint: log/ckpts/ckpt-71\n",
      "Epoch 71 completed.\n",
      "[2210] g_loss: 6.976244926452637 - d_loss: 0.048545461148023605\n",
      "[2220] g_loss: 7.247337818145752 - d_loss: 0.14136123657226562\n",
      "[2230] g_loss: 6.111817359924316 - d_loss: 0.01079302653670311\n",
      "[2232] Saved checkpoint: log/ckpts/ckpt-72\n",
      "Epoch 72 completed.\n",
      "[2240] g_loss: 5.405091762542725 - d_loss: 0.047970108687877655\n",
      "[2250] g_loss: 8.458430290222168 - d_loss: 0.14349684119224548\n",
      "[2260] g_loss: 5.3351969718933105 - d_loss: 0.019717369228601456\n",
      "[2263] Saved checkpoint: log/ckpts/ckpt-73\n",
      "Epoch 73 completed.\n",
      "[2270] g_loss: 4.796555519104004 - d_loss: 0.052513547241687775\n",
      "[2280] g_loss: 5.799550533294678 - d_loss: 0.02570180967450142\n",
      "[2290] g_loss: 6.117033958435059 - d_loss: 0.04463091120123863\n",
      "[2294] Saved checkpoint: log/ckpts/ckpt-74\n",
      "Epoch 74 completed.\n",
      "[2300] g_loss: 6.91843318939209 - d_loss: 0.023272953927516937\n",
      "[2310] g_loss: 6.189743518829346 - d_loss: 0.02967943623661995\n",
      "[2320] g_loss: 7.524411678314209 - d_loss: 0.12811686098575592\n",
      "[2325] Saved checkpoint: log/ckpts/ckpt-75\n",
      "Epoch 75 completed.\n",
      "[2330] g_loss: 4.522894859313965 - d_loss: 0.04872888699173927\n",
      "[2340] g_loss: 4.3727569580078125 - d_loss: 0.04461873322725296\n",
      "[2350] g_loss: 6.364233016967773 - d_loss: 0.05603977292776108\n",
      "[2356] Saved checkpoint: log/ckpts/ckpt-76\n",
      "Epoch 76 completed.\n",
      "[2360] g_loss: 8.191619873046875 - d_loss: 0.06303189694881439\n",
      "[2370] g_loss: 5.929469585418701 - d_loss: 0.029161619022488594\n",
      "[2380] g_loss: 6.783766746520996 - d_loss: 0.05162039026618004\n",
      "[2387] Saved checkpoint: log/ckpts/ckpt-77\n",
      "Epoch 77 completed.\n",
      "[2390] g_loss: 8.140233993530273 - d_loss: 0.005932116415351629\n",
      "[2400] g_loss: 5.490550994873047 - d_loss: 0.032293178141117096\n",
      "[2410] g_loss: 5.946951866149902 - d_loss: 0.018386296927928925\n",
      "[2418] Saved checkpoint: log/ckpts/ckpt-78\n",
      "Epoch 78 completed.\n",
      "[2420] g_loss: 7.110808372497559 - d_loss: 0.019310349598526955\n",
      "[2430] g_loss: 12.468086242675781 - d_loss: 0.004958381876349449\n",
      "[2440] g_loss: 5.247363090515137 - d_loss: 0.07493605464696884\n",
      "[2449] Saved checkpoint: log/ckpts/ckpt-79\n",
      "Epoch 79 completed.\n",
      "[2450] g_loss: 6.025437355041504 - d_loss: 0.046466462314128876\n",
      "[2460] g_loss: 6.898367881774902 - d_loss: 0.0264865905046463\n",
      "[2470] g_loss: 6.696297645568848 - d_loss: 0.02629717066884041\n",
      "[2480] g_loss: 9.336357116699219 - d_loss: 0.09984522312879562\n",
      "[2480] Saved checkpoint: log/ckpts/ckpt-80\n",
      "Epoch 80 completed.\n",
      "[2490] g_loss: 6.309354782104492 - d_loss: 0.013656886294484138\n",
      "[2500] g_loss: 5.477791786193848 - d_loss: 0.022234048694372177\n",
      "[2510] g_loss: 4.059617042541504 - d_loss: 0.04053039103746414\n",
      "[2511] Saved checkpoint: log/ckpts/ckpt-81\n",
      "Epoch 81 completed.\n",
      "[2520] g_loss: 5.248501300811768 - d_loss: 0.010989077389240265\n",
      "[2530] g_loss: 6.283562183380127 - d_loss: 0.021029457449913025\n",
      "[2540] g_loss: 5.961528778076172 - d_loss: 0.04526981711387634\n",
      "[2542] Saved checkpoint: log/ckpts/ckpt-82\n",
      "Epoch 82 completed.\n",
      "[2550] g_loss: 6.456427097320557 - d_loss: 0.006193416193127632\n",
      "[2560] g_loss: 3.9050886631011963 - d_loss: 0.10919931530952454\n",
      "[2570] g_loss: 3.343128204345703 - d_loss: 0.0641443133354187\n",
      "[2573] Saved checkpoint: log/ckpts/ckpt-83\n",
      "Epoch 83 completed.\n",
      "[2580] g_loss: 4.890955924987793 - d_loss: 0.04047917202115059\n",
      "[2590] g_loss: 5.836461067199707 - d_loss: 0.029419880360364914\n",
      "[2600] g_loss: 6.337800979614258 - d_loss: 0.08201534301042557\n",
      "[2604] Saved checkpoint: log/ckpts/ckpt-84\n",
      "Epoch 84 completed.\n",
      "[2610] g_loss: 5.232673645019531 - d_loss: 0.0336313396692276\n",
      "[2620] g_loss: 7.719499588012695 - d_loss: 0.08159784972667694\n",
      "[2630] g_loss: 4.880985260009766 - d_loss: 0.03389028459787369\n",
      "[2635] Saved checkpoint: log/ckpts/ckpt-85\n",
      "Epoch 85 completed.\n",
      "[2640] g_loss: 8.581607818603516 - d_loss: 0.00412122905254364\n",
      "[2650] g_loss: 2.635153293609619 - d_loss: 0.21060355007648468\n",
      "[2660] g_loss: 6.9509429931640625 - d_loss: 0.08467646688222885\n",
      "[2666] Saved checkpoint: log/ckpts/ckpt-86\n",
      "Epoch 86 completed.\n",
      "[2670] g_loss: 8.96702766418457 - d_loss: 0.0949082151055336\n",
      "[2680] g_loss: 9.356646537780762 - d_loss: 0.013460716232657433\n",
      "[2690] g_loss: 8.167465209960938 - d_loss: 0.6925753355026245\n",
      "[2697] Saved checkpoint: log/ckpts/ckpt-87\n",
      "Epoch 87 completed.\n",
      "[2700] g_loss: 14.995569229125977 - d_loss: 0.007085540797561407\n",
      "[2710] g_loss: 7.965776443481445 - d_loss: 0.013535032980144024\n",
      "[2720] g_loss: 6.651916980743408 - d_loss: 0.048339031636714935\n",
      "[2728] Saved checkpoint: log/ckpts/ckpt-88\n",
      "Epoch 88 completed.\n",
      "[2730] g_loss: 6.287919998168945 - d_loss: 0.01845794916152954\n",
      "[2740] g_loss: 3.4563074111938477 - d_loss: 0.14077511429786682\n",
      "[2750] g_loss: 6.1794233322143555 - d_loss: 0.009001747705042362\n",
      "[2759] Saved checkpoint: log/ckpts/ckpt-89\n",
      "Epoch 89 completed.\n",
      "[2760] g_loss: 5.889128684997559 - d_loss: 0.05461025983095169\n",
      "[2770] g_loss: 5.157526969909668 - d_loss: 0.021011754870414734\n",
      "[2780] g_loss: 8.254141807556152 - d_loss: 0.008103073574602604\n",
      "[2790] g_loss: 6.674556732177734 - d_loss: 0.01655922457575798\n",
      "[2790] Saved checkpoint: log/ckpts/ckpt-90\n",
      "Epoch 90 completed.\n",
      "[2800] g_loss: 7.622493267059326 - d_loss: 0.09037872403860092\n",
      "[2810] g_loss: 6.458909034729004 - d_loss: 0.02646041475236416\n",
      "[2820] g_loss: 7.383572578430176 - d_loss: 0.025259941816329956\n",
      "[2821] Saved checkpoint: log/ckpts/ckpt-91\n",
      "Epoch 91 completed.\n",
      "[2830] g_loss: 5.780189514160156 - d_loss: 0.056793197989463806\n",
      "[2840] g_loss: 6.4461669921875 - d_loss: 0.01397641934454441\n",
      "[2850] g_loss: 3.451631546020508 - d_loss: 0.0894138514995575\n",
      "[2852] Saved checkpoint: log/ckpts/ckpt-92\n",
      "Epoch 92 completed.\n",
      "[2860] g_loss: 5.976480484008789 - d_loss: 0.02893749438226223\n",
      "[2870] g_loss: 5.674349784851074 - d_loss: 0.05123979225754738\n",
      "[2880] g_loss: 4.743403434753418 - d_loss: 0.07424166053533554\n",
      "[2883] Saved checkpoint: log/ckpts/ckpt-93\n",
      "Epoch 93 completed.\n",
      "[2890] g_loss: 7.597214698791504 - d_loss: 0.020460834726691246\n",
      "[2900] g_loss: 3.1219921112060547 - d_loss: 0.13979096710681915\n",
      "[2910] g_loss: 4.742368698120117 - d_loss: 0.056634366512298584\n",
      "[2914] Saved checkpoint: log/ckpts/ckpt-94\n",
      "Epoch 94 completed.\n",
      "[2920] g_loss: 6.319100379943848 - d_loss: 0.03207991272211075\n",
      "[2930] g_loss: 8.138815879821777 - d_loss: 0.01293306052684784\n",
      "[2940] g_loss: 5.033169269561768 - d_loss: 0.04592598229646683\n",
      "[2945] Saved checkpoint: log/ckpts/ckpt-95\n",
      "Epoch 95 completed.\n",
      "[2950] g_loss: 5.129585266113281 - d_loss: 0.07614679634571075\n",
      "[2960] g_loss: 9.894968032836914 - d_loss: 0.019044246524572372\n",
      "[2970] g_loss: 5.120754241943359 - d_loss: 0.027650615200400352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2976] Saved checkpoint: log/ckpts/ckpt-96\n",
      "Epoch 96 completed.\n",
      "[2980] g_loss: 6.43903112411499 - d_loss: 0.11435404419898987\n",
      "[2990] g_loss: 3.0879011154174805 - d_loss: 0.09479649364948273\n",
      "[3000] g_loss: 5.903908729553223 - d_loss: 0.012414843775331974\n",
      "[3007] Saved checkpoint: log/ckpts/ckpt-97\n",
      "Epoch 97 completed.\n",
      "[3010] g_loss: 2.98576021194458 - d_loss: 0.13503119349479675\n",
      "[3020] g_loss: 8.597700119018555 - d_loss: 0.0060937367379665375\n",
      "[3030] g_loss: 8.765692710876465 - d_loss: 0.12210363149642944\n",
      "[3038] Saved checkpoint: log/ckpts/ckpt-98\n",
      "Epoch 98 completed.\n",
      "[3040] g_loss: 6.7991509437561035 - d_loss: 0.018372897058725357\n",
      "[3050] g_loss: 2.7371177673339844 - d_loss: 0.19837231934070587\n",
      "[3060] g_loss: 4.997127056121826 - d_loss: 0.015219205990433693\n",
      "[3069] Saved checkpoint: log/ckpts/ckpt-99\n",
      "Epoch 99 completed.\n",
      "[3070] g_loss: 7.5970354080200195 - d_loss: 0.10036138445138931\n",
      "[3080] g_loss: 6.142281532287598 - d_loss: 0.052822865545749664\n",
      "[3090] g_loss: 8.03345012664795 - d_loss: 0.013791016303002834\n",
      "[3100] g_loss: 7.591034412384033 - d_loss: 0.025911279022693634\n",
      "[3100] Saved checkpoint: log/ckpts/ckpt-100\n",
      "Epoch 100 completed.\n",
      "[3110] g_loss: 5.6929192543029785 - d_loss: 0.010776795446872711\n",
      "[3120] g_loss: 6.3631062507629395 - d_loss: 0.026380516588687897\n",
      "[3130] g_loss: 10.429636001586914 - d_loss: 0.09643827378749847\n",
      "[3131] Saved checkpoint: log/ckpts/ckpt-101\n",
      "Epoch 101 completed.\n",
      "[3140] g_loss: 6.6617045402526855 - d_loss: 0.07555137574672699\n",
      "[3150] g_loss: 7.209555625915527 - d_loss: 0.02112990990281105\n",
      "[3160] g_loss: 2.582980155944824 - d_loss: 0.14916682243347168\n",
      "[3162] Saved checkpoint: log/ckpts/ckpt-102\n",
      "Epoch 102 completed.\n",
      "[3170] g_loss: 8.083979606628418 - d_loss: 0.0035397878382354975\n",
      "[3180] g_loss: 7.483147144317627 - d_loss: 0.054640110582113266\n",
      "[3190] g_loss: 7.511968612670898 - d_loss: 0.024727536365389824\n",
      "[3193] Saved checkpoint: log/ckpts/ckpt-103\n",
      "Epoch 103 completed.\n",
      "[3200] g_loss: 7.595152378082275 - d_loss: 0.2742205262184143\n",
      "[3210] g_loss: 6.703069686889648 - d_loss: 0.03051384910941124\n",
      "[3220] g_loss: 9.241741180419922 - d_loss: 0.005086507182568312\n",
      "[3224] Saved checkpoint: log/ckpts/ckpt-104\n",
      "Epoch 104 completed.\n",
      "[3230] g_loss: 7.349794387817383 - d_loss: 0.012730717658996582\n",
      "[3240] g_loss: 3.898648738861084 - d_loss: 0.06302493810653687\n",
      "[3250] g_loss: 6.108394145965576 - d_loss: 0.008321125991642475\n",
      "[3255] Saved checkpoint: log/ckpts/ckpt-105\n",
      "Epoch 105 completed.\n",
      "[3260] g_loss: 6.854676246643066 - d_loss: 0.12516187131404877\n",
      "[3270] g_loss: 6.838481903076172 - d_loss: 0.014331788755953312\n",
      "[3280] g_loss: 9.100763320922852 - d_loss: 0.01463123969733715\n",
      "[3286] Saved checkpoint: log/ckpts/ckpt-106\n",
      "Epoch 106 completed.\n",
      "[3290] g_loss: 6.74069881439209 - d_loss: 0.005975823849439621\n",
      "[3300] g_loss: 5.715353965759277 - d_loss: 0.07824171334505081\n",
      "[3310] g_loss: 5.321155548095703 - d_loss: 0.012695052661001682\n",
      "[3317] Saved checkpoint: log/ckpts/ckpt-107\n",
      "Epoch 107 completed.\n",
      "[3320] g_loss: 8.200407028198242 - d_loss: 0.010319788008928299\n",
      "[3330] g_loss: 5.628454685211182 - d_loss: 0.05701858550310135\n",
      "[3340] g_loss: 7.924499034881592 - d_loss: 0.00580438319593668\n",
      "[3348] Saved checkpoint: log/ckpts/ckpt-108\n",
      "Epoch 108 completed.\n",
      "[3350] g_loss: 7.637119293212891 - d_loss: 0.08481509983539581\n",
      "[3360] g_loss: 11.175785064697266 - d_loss: 0.03173636645078659\n",
      "[3370] g_loss: 7.127860069274902 - d_loss: 0.06104564294219017\n",
      "[3379] Saved checkpoint: log/ckpts/ckpt-109\n",
      "Epoch 109 completed.\n",
      "[3380] g_loss: 6.01484489440918 - d_loss: 0.09287680685520172\n",
      "[3390] g_loss: 8.403072357177734 - d_loss: 0.033379945904016495\n",
      "[3400] g_loss: 7.262409210205078 - d_loss: 0.01403487753123045\n",
      "[3410] g_loss: 8.2332763671875 - d_loss: 0.12297603487968445\n",
      "[3410] Saved checkpoint: log/ckpts/ckpt-110\n",
      "Epoch 110 completed.\n",
      "[3420] g_loss: 6.593990325927734 - d_loss: 0.031309690326452255\n",
      "[3430] g_loss: 6.610233783721924 - d_loss: 0.08791027963161469\n",
      "[3440] g_loss: 4.653254508972168 - d_loss: 0.07650293409824371\n",
      "[3441] Saved checkpoint: log/ckpts/ckpt-111\n",
      "Epoch 111 completed.\n",
      "[3450] g_loss: 7.948429107666016 - d_loss: 0.06527523696422577\n",
      "[3460] g_loss: 10.734336853027344 - d_loss: 0.06998859345912933\n",
      "[3470] g_loss: 8.92675495147705 - d_loss: 0.033678773790597916\n",
      "[3472] Saved checkpoint: log/ckpts/ckpt-112\n",
      "Epoch 112 completed.\n",
      "[3480] g_loss: 4.800742149353027 - d_loss: 0.06579017639160156\n",
      "[3490] g_loss: 4.504640579223633 - d_loss: 0.0621713250875473\n",
      "[3500] g_loss: 4.856070518493652 - d_loss: 0.06944189965724945\n",
      "[3503] Saved checkpoint: log/ckpts/ckpt-113\n",
      "Epoch 113 completed.\n",
      "[3510] g_loss: 3.20651912689209 - d_loss: 0.31390780210494995\n",
      "[3520] g_loss: 7.734225749969482 - d_loss: 0.0051498329266905785\n",
      "[3530] g_loss: 8.31630802154541 - d_loss: 0.008375406265258789\n",
      "[3534] Saved checkpoint: log/ckpts/ckpt-114\n",
      "Epoch 114 completed.\n",
      "[3540] g_loss: 2.706019401550293 - d_loss: 0.15291041135787964\n",
      "[3550] g_loss: 5.462071418762207 - d_loss: 0.06185264140367508\n",
      "[3560] g_loss: 6.071435451507568 - d_loss: 0.0594378337264061\n",
      "[3565] Saved checkpoint: log/ckpts/ckpt-115\n",
      "Epoch 115 completed.\n",
      "[3570] g_loss: 8.641162872314453 - d_loss: 0.10619290173053741\n",
      "[3580] g_loss: 5.882979393005371 - d_loss: 0.07259339839220047\n",
      "[3590] g_loss: 8.803876876831055 - d_loss: 0.031177416443824768\n",
      "[3596] Saved checkpoint: log/ckpts/ckpt-116\n",
      "Epoch 116 completed.\n",
      "[3600] g_loss: 8.04365348815918 - d_loss: 0.053798288106918335\n",
      "[3610] g_loss: 7.121156692504883 - d_loss: 0.028977692127227783\n",
      "[3620] g_loss: 6.164844512939453 - d_loss: 0.13803929090499878\n",
      "[3627] Saved checkpoint: log/ckpts/ckpt-117\n",
      "Epoch 117 completed.\n",
      "[3630] g_loss: 9.49962329864502 - d_loss: 0.017753738909959793\n",
      "[3640] g_loss: 7.726578235626221 - d_loss: 0.004808748606592417\n",
      "[3650] g_loss: 4.631408214569092 - d_loss: 0.02069474384188652\n",
      "[3658] Saved checkpoint: log/ckpts/ckpt-118\n",
      "Epoch 118 completed.\n",
      "[3660] g_loss: 6.0054473876953125 - d_loss: 0.01666202023625374\n",
      "[3670] g_loss: 3.787543296813965 - d_loss: 0.06494877487421036\n",
      "[3680] g_loss: 7.133456707000732 - d_loss: 0.05339265614748001\n",
      "[3689] Saved checkpoint: log/ckpts/ckpt-119\n",
      "Epoch 119 completed.\n",
      "[3690] g_loss: 5.929947853088379 - d_loss: 0.20716214179992676\n",
      "[3700] g_loss: 6.122759819030762 - d_loss: 0.03159043937921524\n",
      "[3710] g_loss: 6.524880886077881 - d_loss: 0.2134418487548828\n",
      "[3720] g_loss: 9.793161392211914 - d_loss: 0.024789635092020035\n",
      "[3720] Saved checkpoint: log/ckpts/ckpt-120\n",
      "Epoch 120 completed.\n",
      "[3730] g_loss: 5.563016891479492 - d_loss: 0.025391288101673126\n",
      "[3740] g_loss: 4.044342041015625 - d_loss: 0.059520017355680466\n",
      "[3750] g_loss: 5.793415069580078 - d_loss: 0.07240847498178482\n",
      "[3751] Saved checkpoint: log/ckpts/ckpt-121\n",
      "Epoch 121 completed.\n",
      "[3760] g_loss: 7.581298828125 - d_loss: 0.03593115136027336\n",
      "[3770] g_loss: 6.988101005554199 - d_loss: 0.021416649222373962\n",
      "[3780] g_loss: 5.010330677032471 - d_loss: 0.04072802513837814\n",
      "[3782] Saved checkpoint: log/ckpts/ckpt-122\n",
      "Epoch 122 completed.\n",
      "[3790] g_loss: 5.820476531982422 - d_loss: 0.009824095293879509\n",
      "[3800] g_loss: 5.783753395080566 - d_loss: 0.05098515748977661\n",
      "[3810] g_loss: 7.648728847503662 - d_loss: 0.062343280762434006\n",
      "[3813] Saved checkpoint: log/ckpts/ckpt-123\n",
      "Epoch 123 completed.\n",
      "[3820] g_loss: 8.578702926635742 - d_loss: 0.007848109118640423\n",
      "[3830] g_loss: 7.808094024658203 - d_loss: 0.06249895691871643\n",
      "[3840] g_loss: 5.316898822784424 - d_loss: 0.08602569997310638\n",
      "[3844] Saved checkpoint: log/ckpts/ckpt-124\n",
      "Epoch 124 completed.\n",
      "[3850] g_loss: 7.902737617492676 - d_loss: 0.02375033125281334\n",
      "[3860] g_loss: 4.401968002319336 - d_loss: 0.0886966809630394\n",
      "[3870] g_loss: 5.397531032562256 - d_loss: 0.06493020057678223\n",
      "[3875] Saved checkpoint: log/ckpts/ckpt-125\n",
      "Epoch 125 completed.\n",
      "[3880] g_loss: 4.984471797943115 - d_loss: 0.019989293068647385\n",
      "[3890] g_loss: 3.87363862991333 - d_loss: 0.05377944931387901\n",
      "[3900] g_loss: 3.690715789794922 - d_loss: 0.06492345035076141\n",
      "[3906] Saved checkpoint: log/ckpts/ckpt-126\n",
      "Epoch 126 completed.\n",
      "[3910] g_loss: 8.432560920715332 - d_loss: 0.02560502663254738\n",
      "[3920] g_loss: 9.975154876708984 - d_loss: 0.13948482275009155\n",
      "[3930] g_loss: 8.905211448669434 - d_loss: 0.08170851320028305\n",
      "[3937] Saved checkpoint: log/ckpts/ckpt-127\n",
      "Epoch 127 completed.\n",
      "[3940] g_loss: 6.290280342102051 - d_loss: 0.027342360466718674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3950] g_loss: 5.7813029289245605 - d_loss: 0.051980119198560715\n",
      "[3960] g_loss: 4.870149612426758 - d_loss: 0.08086930215358734\n",
      "[3968] Saved checkpoint: log/ckpts/ckpt-128\n",
      "Epoch 128 completed.\n",
      "[3970] g_loss: 6.097923755645752 - d_loss: 0.012280765920877457\n",
      "[3980] g_loss: 7.826503753662109 - d_loss: 0.03302852064371109\n",
      "[3990] g_loss: 4.550168037414551 - d_loss: 0.050348229706287384\n",
      "[3999] Saved checkpoint: log/ckpts/ckpt-129\n",
      "Epoch 129 completed.\n",
      "[4000] g_loss: 7.272942543029785 - d_loss: 0.010175928473472595\n",
      "[4010] g_loss: 6.017125129699707 - d_loss: 0.027966944500803947\n",
      "[4020] g_loss: 6.679531097412109 - d_loss: 0.015052175149321556\n",
      "[4030] g_loss: 3.220811128616333 - d_loss: 0.132538840174675\n",
      "[4030] Saved checkpoint: log/ckpts/ckpt-130\n",
      "Epoch 130 completed.\n",
      "[4040] g_loss: 8.776372909545898 - d_loss: 0.012826191261410713\n",
      "[4050] g_loss: 8.682093620300293 - d_loss: 0.0604761578142643\n",
      "[4060] g_loss: 11.920736312866211 - d_loss: 0.1654316484928131\n",
      "[4061] Saved checkpoint: log/ckpts/ckpt-131\n",
      "Epoch 131 completed.\n",
      "[4070] g_loss: 11.261344909667969 - d_loss: 0.0024673864245414734\n",
      "[4080] g_loss: 7.169682502746582 - d_loss: 0.09412293136119843\n",
      "[4090] g_loss: 5.01746940612793 - d_loss: 0.019251931458711624\n",
      "[4092] Saved checkpoint: log/ckpts/ckpt-132\n",
      "Epoch 132 completed.\n",
      "[4100] g_loss: 5.065402984619141 - d_loss: 0.03822651505470276\n",
      "[4110] g_loss: 3.4545955657958984 - d_loss: 0.16214287281036377\n",
      "[4120] g_loss: 2.615159273147583 - d_loss: 0.13551342487335205\n",
      "[4123] Saved checkpoint: log/ckpts/ckpt-133\n",
      "Epoch 133 completed.\n",
      "[4130] g_loss: 6.2461113929748535 - d_loss: 0.017466630786657333\n",
      "[4140] g_loss: 4.648571968078613 - d_loss: 0.024308569729328156\n",
      "[4150] g_loss: 4.740434169769287 - d_loss: 0.048561520874500275\n",
      "[4154] Saved checkpoint: log/ckpts/ckpt-134\n",
      "Epoch 134 completed.\n",
      "[4160] g_loss: 3.92392635345459 - d_loss: 0.09196102619171143\n",
      "[4170] g_loss: 6.684665679931641 - d_loss: 0.020646490156650543\n",
      "[4180] g_loss: 5.85373067855835 - d_loss: 0.009586972184479237\n",
      "[4185] Saved checkpoint: log/ckpts/ckpt-135\n",
      "Epoch 135 completed.\n",
      "[4190] g_loss: 6.814866065979004 - d_loss: 0.01307150349020958\n",
      "[4200] g_loss: 5.461280345916748 - d_loss: 0.044750768691301346\n",
      "[4210] g_loss: 5.234842300415039 - d_loss: 0.06622710078954697\n",
      "[4216] Saved checkpoint: log/ckpts/ckpt-136\n",
      "Epoch 136 completed.\n",
      "[4220] g_loss: 5.211404323577881 - d_loss: 0.02924794889986515\n",
      "[4230] g_loss: 7.265076160430908 - d_loss: 0.12050193548202515\n",
      "[4240] g_loss: 5.348148822784424 - d_loss: 0.07303295284509659\n",
      "[4247] Saved checkpoint: log/ckpts/ckpt-137\n",
      "Epoch 137 completed.\n",
      "[4250] g_loss: 2.0111751556396484 - d_loss: 0.3708437383174896\n",
      "[4260] g_loss: 9.07858943939209 - d_loss: 0.056457262486219406\n",
      "[4270] g_loss: 6.169694900512695 - d_loss: 0.025911644101142883\n",
      "[4278] Saved checkpoint: log/ckpts/ckpt-138\n",
      "Epoch 138 completed.\n",
      "[4280] g_loss: 4.856503486633301 - d_loss: 0.13149502873420715\n",
      "[4290] g_loss: 6.125269889831543 - d_loss: 0.023005245253443718\n",
      "[4300] g_loss: 6.3073601722717285 - d_loss: 0.010554973967373371\n",
      "[4309] Saved checkpoint: log/ckpts/ckpt-139\n",
      "Epoch 139 completed.\n",
      "[4310] g_loss: 3.282869815826416 - d_loss: 0.08427744358778\n",
      "[4320] g_loss: 7.6389617919921875 - d_loss: 0.07297973334789276\n",
      "[4330] g_loss: 6.983111381530762 - d_loss: 0.03346025571227074\n",
      "[4340] g_loss: 8.00244426727295 - d_loss: 0.1600339412689209\n",
      "[4340] Saved checkpoint: log/ckpts/ckpt-140\n",
      "Epoch 140 completed.\n",
      "[4350] g_loss: 7.8602294921875 - d_loss: 0.017814569175243378\n",
      "[4360] g_loss: 4.265381813049316 - d_loss: 0.0801767110824585\n",
      "[4370] g_loss: 6.17286491394043 - d_loss: 0.01112245861440897\n",
      "[4371] Saved checkpoint: log/ckpts/ckpt-141\n",
      "Epoch 141 completed.\n",
      "[4380] g_loss: 5.1057658195495605 - d_loss: 0.03972996771335602\n",
      "[4390] g_loss: 5.477210998535156 - d_loss: 0.02147938311100006\n",
      "[4400] g_loss: 6.440493583679199 - d_loss: 0.13073252141475677\n",
      "[4402] Saved checkpoint: log/ckpts/ckpt-142\n",
      "Epoch 142 completed.\n",
      "[4410] g_loss: 4.822760581970215 - d_loss: 0.029834210872650146\n",
      "[4420] g_loss: 5.568821907043457 - d_loss: 0.08199842274188995\n",
      "[4430] g_loss: 7.479938983917236 - d_loss: 0.009091206826269627\n",
      "[4433] Saved checkpoint: log/ckpts/ckpt-143\n",
      "Epoch 143 completed.\n",
      "[4440] g_loss: 6.790292263031006 - d_loss: 0.022542057558894157\n",
      "[4450] g_loss: 4.140905380249023 - d_loss: 0.04146096110343933\n",
      "[4460] g_loss: 4.429442405700684 - d_loss: 0.0609133318066597\n",
      "[4464] Saved checkpoint: log/ckpts/ckpt-144\n",
      "Epoch 144 completed.\n",
      "[4470] g_loss: 7.906202793121338 - d_loss: 0.030438173562288284\n",
      "[4480] g_loss: 6.0589799880981445 - d_loss: 0.0844893604516983\n",
      "[4490] g_loss: 5.336975574493408 - d_loss: 0.028546039015054703\n",
      "[4495] Saved checkpoint: log/ckpts/ckpt-145\n",
      "Epoch 145 completed.\n",
      "[4500] g_loss: 7.720976829528809 - d_loss: 0.006768542341887951\n",
      "[4510] g_loss: 8.578608512878418 - d_loss: 0.01946299895644188\n",
      "[4520] g_loss: 7.9014763832092285 - d_loss: 0.004282461944967508\n",
      "[4526] Saved checkpoint: log/ckpts/ckpt-146\n",
      "Epoch 146 completed.\n",
      "[4530] g_loss: 9.178970336914062 - d_loss: 0.07134860754013062\n",
      "[4540] g_loss: 5.388503074645996 - d_loss: 0.0340721532702446\n",
      "[4550] g_loss: 5.902748107910156 - d_loss: 0.032680485397577286\n",
      "[4557] Saved checkpoint: log/ckpts/ckpt-147\n",
      "Epoch 147 completed.\n",
      "[4560] g_loss: 7.147795677185059 - d_loss: 0.021298808977007866\n",
      "[4570] g_loss: 6.0982985496521 - d_loss: 0.06131000816822052\n",
      "[4580] g_loss: 7.176204681396484 - d_loss: 0.0030024643056094646\n",
      "[4588] Saved checkpoint: log/ckpts/ckpt-148\n",
      "Epoch 148 completed.\n",
      "[4590] g_loss: 4.661084175109863 - d_loss: 0.03023863583803177\n",
      "[4600] g_loss: 6.103211402893066 - d_loss: 0.01114970538765192\n",
      "[4610] g_loss: 6.185582160949707 - d_loss: 0.009278163313865662\n",
      "[4619] Saved checkpoint: log/ckpts/ckpt-149\n",
      "Epoch 149 completed.\n",
      "[4620] g_loss: 4.536919593811035 - d_loss: 0.04177040234208107\n",
      "[4630] g_loss: 7.683071136474609 - d_loss: 0.038239359855651855\n",
      "[4640] g_loss: 7.6269450187683105 - d_loss: 0.0494750440120697\n",
      "[4650] g_loss: 7.411038398742676 - d_loss: 0.09668247401714325\n",
      "[4650] Saved checkpoint: log/ckpts/ckpt-150\n",
      "Epoch 150 completed.\n",
      "[4660] g_loss: 7.672810077667236 - d_loss: 0.002361205406486988\n",
      "[4670] g_loss: 6.171247482299805 - d_loss: 0.02934734895825386\n",
      "[4680] g_loss: 4.800797462463379 - d_loss: 0.03604109212756157\n",
      "[4681] Saved checkpoint: log/ckpts/ckpt-151\n",
      "Epoch 151 completed.\n",
      "[4690] g_loss: 7.461233615875244 - d_loss: 0.0036575831472873688\n",
      "[4700] g_loss: 5.299602508544922 - d_loss: 0.05748818442225456\n",
      "[4710] g_loss: 3.2363882064819336 - d_loss: 0.08190686255693436\n",
      "[4712] Saved checkpoint: log/ckpts/ckpt-152\n",
      "Epoch 152 completed.\n",
      "[4720] g_loss: 3.2352921962738037 - d_loss: 0.12698133289813995\n",
      "[4730] g_loss: 6.068717002868652 - d_loss: 0.0255175419151783\n",
      "[4740] g_loss: 9.890144348144531 - d_loss: 0.3500968813896179\n",
      "[4743] Saved checkpoint: log/ckpts/ckpt-153\n",
      "Epoch 153 completed.\n",
      "[4750] g_loss: 12.018871307373047 - d_loss: 0.057831794023513794\n",
      "[4760] g_loss: 13.006373405456543 - d_loss: 0.05304485931992531\n",
      "[4770] g_loss: 9.95693588256836 - d_loss: 0.0036613447591662407\n",
      "[4774] Saved checkpoint: log/ckpts/ckpt-154\n",
      "Epoch 154 completed.\n",
      "[4780] g_loss: 14.05787467956543 - d_loss: 0.07761538773775101\n",
      "[4790] g_loss: 10.745573043823242 - d_loss: 0.004026156384497881\n",
      "[4800] g_loss: 8.12364673614502 - d_loss: 0.013343150727450848\n",
      "[4805] Saved checkpoint: log/ckpts/ckpt-155\n",
      "Epoch 155 completed.\n",
      "[4810] g_loss: 6.481906890869141 - d_loss: 0.0602482333779335\n",
      "[4820] g_loss: 6.204505920410156 - d_loss: 0.02461087331175804\n",
      "[4830] g_loss: 7.549056529998779 - d_loss: 0.016960131004452705\n",
      "[4836] Saved checkpoint: log/ckpts/ckpt-156\n",
      "Epoch 156 completed.\n",
      "[4840] g_loss: 8.579769134521484 - d_loss: 0.011927533894777298\n",
      "[4850] g_loss: 7.545353412628174 - d_loss: 0.08953149616718292\n",
      "[4860] g_loss: 5.679786682128906 - d_loss: 0.04001099243760109\n",
      "[4867] Saved checkpoint: log/ckpts/ckpt-157\n",
      "Epoch 157 completed.\n",
      "[4870] g_loss: 5.279721736907959 - d_loss: 0.07302004843950272\n",
      "[4880] g_loss: 5.1135053634643555 - d_loss: 0.0209784135222435\n",
      "[4890] g_loss: 4.239927768707275 - d_loss: 0.041631802916526794\n",
      "[4898] Saved checkpoint: log/ckpts/ckpt-158\n",
      "Epoch 158 completed.\n",
      "[4900] g_loss: 4.790071487426758 - d_loss: 0.08296432346105576\n",
      "[4910] g_loss: 6.7795586585998535 - d_loss: 0.003263755701482296\n",
      "[4920] g_loss: 7.884906768798828 - d_loss: 0.11357790231704712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4929] Saved checkpoint: log/ckpts/ckpt-159\n",
      "Epoch 159 completed.\n",
      "[4930] g_loss: 3.46563720703125 - d_loss: 0.08316778391599655\n",
      "[4940] g_loss: 7.359714508056641 - d_loss: 0.019024085253477097\n",
      "[4950] g_loss: 4.225822448730469 - d_loss: 0.05300651118159294\n",
      "[4960] g_loss: 7.210484504699707 - d_loss: 0.05447511374950409\n",
      "[4960] Saved checkpoint: log/ckpts/ckpt-160\n",
      "Epoch 160 completed.\n",
      "[4970] g_loss: 9.52499008178711 - d_loss: 0.01345040649175644\n",
      "[4980] g_loss: 7.12285852432251 - d_loss: 0.0024622613564133644\n",
      "[4990] g_loss: 4.490544319152832 - d_loss: 0.07245595008134842\n",
      "[4991] Saved checkpoint: log/ckpts/ckpt-161\n",
      "Epoch 161 completed.\n",
      "[5000] g_loss: 5.877676010131836 - d_loss: 0.031324271112680435\n",
      "[5010] g_loss: 4.250940322875977 - d_loss: 0.08388318121433258\n",
      "[5020] g_loss: 6.528748035430908 - d_loss: 0.012937605381011963\n",
      "[5022] Saved checkpoint: log/ckpts/ckpt-162\n",
      "Epoch 162 completed.\n",
      "[5030] g_loss: 4.097959518432617 - d_loss: 0.07689115405082703\n",
      "[5040] g_loss: 2.335324287414551 - d_loss: 0.1706964075565338\n",
      "[5050] g_loss: 4.136470794677734 - d_loss: 0.08250458538532257\n",
      "[5053] Saved checkpoint: log/ckpts/ckpt-163\n",
      "Epoch 163 completed.\n",
      "[5060] g_loss: 4.665454864501953 - d_loss: 0.03354407846927643\n",
      "[5070] g_loss: 4.208637237548828 - d_loss: 0.06361649185419083\n",
      "[5080] g_loss: 5.740657806396484 - d_loss: 0.047045305371284485\n",
      "[5084] Saved checkpoint: log/ckpts/ckpt-164\n",
      "Epoch 164 completed.\n",
      "[5090] g_loss: 6.540856838226318 - d_loss: 0.03950228914618492\n",
      "[5100] g_loss: 4.1526103019714355 - d_loss: 0.1594175398349762\n",
      "[5110] g_loss: 6.431149482727051 - d_loss: 0.06038779020309448\n",
      "[5115] Saved checkpoint: log/ckpts/ckpt-165\n",
      "Epoch 165 completed.\n",
      "[5120] g_loss: 5.751930236816406 - d_loss: 0.028164619579911232\n",
      "[5130] g_loss: 6.530097007751465 - d_loss: 0.03448051959276199\n",
      "[5140] g_loss: 7.881986618041992 - d_loss: 0.01152343675494194\n",
      "[5146] Saved checkpoint: log/ckpts/ckpt-166\n",
      "Epoch 166 completed.\n",
      "[5150] g_loss: 4.199286460876465 - d_loss: 0.03879217803478241\n",
      "[5160] g_loss: 4.393392562866211 - d_loss: 0.04178633168339729\n",
      "[5170] g_loss: 8.127248764038086 - d_loss: 0.18898385763168335\n",
      "[5177] Saved checkpoint: log/ckpts/ckpt-167\n",
      "Epoch 167 completed.\n",
      "[5180] g_loss: 10.922419548034668 - d_loss: 0.009516367688775063\n",
      "[5190] g_loss: 7.407322883605957 - d_loss: 0.011557282879948616\n",
      "[5200] g_loss: 8.65787410736084 - d_loss: 0.011183828115463257\n",
      "[5208] Saved checkpoint: log/ckpts/ckpt-168\n",
      "Epoch 168 completed.\n",
      "[5210] g_loss: 8.957324981689453 - d_loss: 0.03512777388095856\n",
      "[5220] g_loss: 7.149035930633545 - d_loss: 0.08096317946910858\n",
      "[5230] g_loss: 6.6827239990234375 - d_loss: 0.011555612087249756\n",
      "[5239] Saved checkpoint: log/ckpts/ckpt-169\n",
      "Epoch 169 completed.\n",
      "[5240] g_loss: 7.278223037719727 - d_loss: 0.0999835729598999\n",
      "[5250] g_loss: 5.855383396148682 - d_loss: 0.014039784669876099\n",
      "[5260] g_loss: 2.8889894485473633 - d_loss: 0.18625348806381226\n",
      "[5270] g_loss: 8.265402793884277 - d_loss: 0.006999136880040169\n",
      "[5270] Saved checkpoint: log/ckpts/ckpt-170\n",
      "Epoch 170 completed.\n",
      "[5280] g_loss: 7.296134948730469 - d_loss: 0.020237626507878304\n",
      "[5290] g_loss: 4.555221080780029 - d_loss: 0.06338703632354736\n",
      "[5300] g_loss: 3.545279026031494 - d_loss: 0.0710129588842392\n",
      "[5301] Saved checkpoint: log/ckpts/ckpt-171\n",
      "Epoch 171 completed.\n",
      "[5310] g_loss: 3.1748712062835693 - d_loss: 0.0721706971526146\n",
      "[5320] g_loss: 4.9073357582092285 - d_loss: 0.02038418874144554\n",
      "[5330] g_loss: 4.411720275878906 - d_loss: 0.06739423424005508\n",
      "[5332] Saved checkpoint: log/ckpts/ckpt-172\n",
      "Epoch 172 completed.\n",
      "[5340] g_loss: 3.7905116081237793 - d_loss: 0.060598019510507584\n",
      "[5350] g_loss: 5.426542282104492 - d_loss: 0.016241565346717834\n",
      "[5360] g_loss: 2.7296295166015625 - d_loss: 0.12607595324516296\n",
      "[5363] Saved checkpoint: log/ckpts/ckpt-173\n",
      "Epoch 173 completed.\n",
      "[5370] g_loss: 4.185910224914551 - d_loss: 0.032644085586071014\n",
      "[5380] g_loss: 5.926923751831055 - d_loss: 0.00829936284571886\n",
      "[5390] g_loss: 3.045124053955078 - d_loss: 0.10467278212308884\n",
      "[5394] Saved checkpoint: log/ckpts/ckpt-174\n",
      "Epoch 174 completed.\n",
      "[5400] g_loss: 4.1493048667907715 - d_loss: 0.0563679039478302\n",
      "[5410] g_loss: 4.529204368591309 - d_loss: 0.020089082419872284\n",
      "[5420] g_loss: 4.583803176879883 - d_loss: 0.03603869676589966\n",
      "[5425] Saved checkpoint: log/ckpts/ckpt-175\n",
      "Epoch 175 completed.\n",
      "[5430] g_loss: 5.718023777008057 - d_loss: 0.11425764858722687\n",
      "[5440] g_loss: 7.13623046875 - d_loss: 0.009909594431519508\n",
      "[5450] g_loss: 5.803067207336426 - d_loss: 0.02799386903643608\n",
      "[5456] Saved checkpoint: log/ckpts/ckpt-176\n",
      "Epoch 176 completed.\n",
      "[5460] g_loss: 6.310912132263184 - d_loss: 0.10691043734550476\n",
      "[5470] g_loss: 5.458994388580322 - d_loss: 0.010726113803684711\n",
      "[5480] g_loss: 5.94145393371582 - d_loss: 0.03289125859737396\n",
      "[5487] Saved checkpoint: log/ckpts/ckpt-177\n",
      "Epoch 177 completed.\n",
      "[5490] g_loss: 4.792212963104248 - d_loss: 0.0677606537938118\n",
      "[5500] g_loss: 6.824143886566162 - d_loss: 0.12538796663284302\n",
      "[5510] g_loss: 7.00157356262207 - d_loss: 0.03951669856905937\n",
      "[5518] Saved checkpoint: log/ckpts/ckpt-178\n",
      "Epoch 178 completed.\n",
      "[5520] g_loss: 6.768426418304443 - d_loss: 0.01596192456781864\n",
      "[5530] g_loss: 7.126633167266846 - d_loss: 0.13094688951969147\n",
      "[5540] g_loss: 7.221871852874756 - d_loss: 0.007724984548985958\n",
      "[5549] Saved checkpoint: log/ckpts/ckpt-179\n",
      "Epoch 179 completed.\n",
      "[5550] g_loss: 9.11650276184082 - d_loss: 0.06351509690284729\n",
      "[5560] g_loss: 7.1175127029418945 - d_loss: 0.020895909518003464\n",
      "[5570] g_loss: 4.891078472137451 - d_loss: 0.04122622683644295\n",
      "[5580] g_loss: 6.012988567352295 - d_loss: 0.043983280658721924\n",
      "[5580] Saved checkpoint: log/ckpts/ckpt-180\n",
      "Epoch 180 completed.\n",
      "[5590] g_loss: 10.072800636291504 - d_loss: 0.1263846755027771\n",
      "[5600] g_loss: 10.20910930633545 - d_loss: 0.0022777707781642675\n",
      "[5610] g_loss: 9.032078742980957 - d_loss: 0.0032835067249834538\n",
      "[5611] Saved checkpoint: log/ckpts/ckpt-181\n",
      "Epoch 181 completed.\n",
      "[5620] g_loss: 7.352896690368652 - d_loss: 0.005029794294387102\n",
      "[5630] g_loss: 11.404633522033691 - d_loss: 0.29694777727127075\n",
      "[5640] g_loss: 10.69270133972168 - d_loss: 0.050586048513650894\n",
      "[5642] Saved checkpoint: log/ckpts/ckpt-182\n",
      "Epoch 182 completed.\n",
      "[5650] g_loss: 8.681093215942383 - d_loss: 0.16529028117656708\n",
      "[5660] g_loss: 7.473623752593994 - d_loss: 0.07005688548088074\n",
      "[5670] g_loss: 6.277062892913818 - d_loss: 0.012720342725515366\n",
      "[5673] Saved checkpoint: log/ckpts/ckpt-183\n",
      "Epoch 183 completed.\n",
      "[5680] g_loss: 6.599063396453857 - d_loss: 0.05028292536735535\n",
      "[5690] g_loss: 5.356107234954834 - d_loss: 0.04340524598956108\n",
      "[5700] g_loss: 6.565850734710693 - d_loss: 0.020264195278286934\n",
      "[5704] Saved checkpoint: log/ckpts/ckpt-184\n",
      "Epoch 184 completed.\n",
      "[5710] g_loss: 5.959083557128906 - d_loss: 0.01990676112473011\n",
      "[5720] g_loss: 5.227380752563477 - d_loss: 0.08354564011096954\n",
      "[5730] g_loss: 6.283202171325684 - d_loss: 0.02133967913687229\n",
      "[5735] Saved checkpoint: log/ckpts/ckpt-185\n",
      "Epoch 185 completed.\n",
      "[5740] g_loss: 5.539281845092773 - d_loss: 0.04509073123335838\n",
      "[5750] g_loss: 4.739053726196289 - d_loss: 0.08556957542896271\n",
      "[5760] g_loss: 6.741818428039551 - d_loss: 0.020193956792354584\n",
      "[5766] Saved checkpoint: log/ckpts/ckpt-186\n",
      "Epoch 186 completed.\n",
      "[5770] g_loss: 6.894102573394775 - d_loss: 0.023727908730506897\n",
      "[5780] g_loss: 5.132823944091797 - d_loss: 0.02147252857685089\n",
      "[5790] g_loss: 7.752524375915527 - d_loss: 0.011839725077152252\n",
      "[5797] Saved checkpoint: log/ckpts/ckpt-187\n",
      "Epoch 187 completed.\n",
      "[5800] g_loss: 8.63722038269043 - d_loss: 0.0410328283905983\n",
      "[5810] g_loss: 4.839020729064941 - d_loss: 0.013235949911177158\n",
      "[5820] g_loss: 8.113459587097168 - d_loss: 0.008348755538463593\n",
      "[5828] Saved checkpoint: log/ckpts/ckpt-188\n",
      "Epoch 188 completed.\n",
      "[5830] g_loss: 7.150835990905762 - d_loss: 0.017644323408603668\n",
      "[5840] g_loss: 7.067318439483643 - d_loss: 0.010787198320031166\n",
      "[5850] g_loss: 6.74873161315918 - d_loss: 0.007074082735925913\n",
      "[5859] Saved checkpoint: log/ckpts/ckpt-189\n",
      "Epoch 189 completed.\n",
      "[5860] g_loss: 6.331514835357666 - d_loss: 0.06602486968040466\n",
      "[5870] g_loss: 4.995151042938232 - d_loss: 0.037357915192842484\n",
      "[5880] g_loss: 5.157323837280273 - d_loss: 0.020599745213985443\n",
      "[5890] g_loss: 5.073794364929199 - d_loss: 0.021608686074614525\n",
      "[5890] Saved checkpoint: log/ckpts/ckpt-190\n",
      "Epoch 190 completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5900] g_loss: 4.233189582824707 - d_loss: 0.03333602100610733\n",
      "[5910] g_loss: 7.482357025146484 - d_loss: 0.01221203152090311\n",
      "[5920] g_loss: 6.6174750328063965 - d_loss: 0.072931669652462\n",
      "[5921] Saved checkpoint: log/ckpts/ckpt-191\n",
      "Epoch 191 completed.\n",
      "[5930] g_loss: 9.887803077697754 - d_loss: 0.028844282031059265\n",
      "[5940] g_loss: 4.513058185577393 - d_loss: 0.041795726865530014\n",
      "[5950] g_loss: 7.630817413330078 - d_loss: 0.007139756344258785\n",
      "[5952] Saved checkpoint: log/ckpts/ckpt-192\n",
      "Epoch 192 completed.\n",
      "[5960] g_loss: 9.216154098510742 - d_loss: 0.03949076309800148\n",
      "[5970] g_loss: 6.7998247146606445 - d_loss: 0.04309137165546417\n",
      "[5980] g_loss: 4.9447479248046875 - d_loss: 0.019645433872938156\n",
      "[5983] Saved checkpoint: log/ckpts/ckpt-193\n",
      "Epoch 193 completed.\n",
      "[5990] g_loss: 12.490989685058594 - d_loss: 0.4924812614917755\n",
      "[6000] g_loss: 8.926315307617188 - d_loss: 0.0006283631082624197\n",
      "[6010] g_loss: 8.299477577209473 - d_loss: 0.029553081840276718\n",
      "[6014] Saved checkpoint: log/ckpts/ckpt-194\n",
      "Epoch 194 completed.\n",
      "[6020] g_loss: 5.552408218383789 - d_loss: 0.04772990196943283\n",
      "[6030] g_loss: 5.052151203155518 - d_loss: 0.020003503188490868\n",
      "[6040] g_loss: 9.251741409301758 - d_loss: 0.016625571995973587\n",
      "[6045] Saved checkpoint: log/ckpts/ckpt-195\n",
      "Epoch 195 completed.\n",
      "[6050] g_loss: 8.49894905090332 - d_loss: 0.0304426196962595\n",
      "[6060] g_loss: 8.163360595703125 - d_loss: 0.06675945967435837\n",
      "[6070] g_loss: 11.249105453491211 - d_loss: 0.03261125087738037\n",
      "[6076] Saved checkpoint: log/ckpts/ckpt-196\n",
      "Epoch 196 completed.\n",
      "[6080] g_loss: 4.39233922958374 - d_loss: 0.10866902023553848\n",
      "[6090] g_loss: 7.24852180480957 - d_loss: 0.07822254300117493\n",
      "[6100] g_loss: 7.119038105010986 - d_loss: 0.02688104659318924\n",
      "[6107] Saved checkpoint: log/ckpts/ckpt-197\n",
      "Epoch 197 completed.\n",
      "[6110] g_loss: 4.938417434692383 - d_loss: 0.08817307651042938\n",
      "[6120] g_loss: 5.1350812911987305 - d_loss: 0.029982872307300568\n",
      "[6130] g_loss: 7.18206787109375 - d_loss: 0.059993572533130646\n",
      "[6138] Saved checkpoint: log/ckpts/ckpt-198\n",
      "Epoch 198 completed.\n",
      "[6140] g_loss: 6.514098167419434 - d_loss: 0.008502446115016937\n",
      "[6150] g_loss: 3.620450735092163 - d_loss: 0.17025330662727356\n",
      "[6160] g_loss: 5.232802391052246 - d_loss: 0.07205953449010849\n",
      "[6169] Saved checkpoint: log/ckpts/ckpt-199\n",
      "Epoch 199 completed.\n",
      "[6170] g_loss: 9.728428840637207 - d_loss: 0.002519298577681184\n",
      "[6180] g_loss: 6.786968231201172 - d_loss: 0.032213445752859116\n",
      "[6190] g_loss: 5.585814476013184 - d_loss: 0.04132724925875664\n",
      "[6200] g_loss: 6.901397705078125 - d_loss: 0.02428770437836647\n",
      "[6200] Saved checkpoint: log/ckpts/ckpt-200\n",
      "Epoch 200 completed.\n",
      "[6210] g_loss: 7.67739200592041 - d_loss: 0.017460038885474205\n",
      "[6220] g_loss: 6.6148247718811035 - d_loss: 0.006290476769208908\n",
      "[6230] g_loss: 3.275603771209717 - d_loss: 0.15127822756767273\n",
      "[6231] Saved checkpoint: log/ckpts/ckpt-201\n",
      "Epoch 201 completed.\n",
      "[6240] g_loss: 6.828934192657471 - d_loss: 0.012648429721593857\n",
      "[6250] g_loss: 8.786563873291016 - d_loss: 0.014692430384457111\n",
      "[6260] g_loss: 7.09602165222168 - d_loss: 0.050450656563043594\n",
      "[6262] Saved checkpoint: log/ckpts/ckpt-202\n",
      "Epoch 202 completed.\n",
      "[6270] g_loss: 4.710882186889648 - d_loss: 0.055230893194675446\n",
      "[6280] g_loss: 8.318951606750488 - d_loss: 0.07281149923801422\n",
      "[6290] g_loss: 6.6350603103637695 - d_loss: 0.020207587629556656\n",
      "[6293] Saved checkpoint: log/ckpts/ckpt-203\n",
      "Epoch 203 completed.\n",
      "[6300] g_loss: 4.334219932556152 - d_loss: 0.03256423771381378\n",
      "[6310] g_loss: 3.8110482692718506 - d_loss: 0.05642704665660858\n",
      "[6320] g_loss: 5.0106048583984375 - d_loss: 0.015127732418477535\n",
      "[6324] Saved checkpoint: log/ckpts/ckpt-204\n",
      "Epoch 204 completed.\n",
      "[6330] g_loss: 5.9264750480651855 - d_loss: 0.020955296233296394\n",
      "[6340] g_loss: 6.547496318817139 - d_loss: 0.038791313767433167\n",
      "[6350] g_loss: 8.114049911499023 - d_loss: 0.10555364191532135\n",
      "[6355] Saved checkpoint: log/ckpts/ckpt-205\n",
      "Epoch 205 completed.\n",
      "[6360] g_loss: 7.423563480377197 - d_loss: 0.00645278487354517\n",
      "[6370] g_loss: 6.351739883422852 - d_loss: 0.020988428965210915\n",
      "[6380] g_loss: 6.424593925476074 - d_loss: 0.02958710677921772\n",
      "[6386] Saved checkpoint: log/ckpts/ckpt-206\n",
      "Epoch 206 completed.\n",
      "[6390] g_loss: 4.923747539520264 - d_loss: 0.04464476928114891\n",
      "[6400] g_loss: 5.14309024810791 - d_loss: 0.012472360394895077\n",
      "[6410] g_loss: 5.652607440948486 - d_loss: 0.010003739967942238\n",
      "[6417] Saved checkpoint: log/ckpts/ckpt-207\n",
      "Epoch 207 completed.\n",
      "[6420] g_loss: 5.213943958282471 - d_loss: 0.056941937655210495\n",
      "[6430] g_loss: 4.786524772644043 - d_loss: 0.01704717054963112\n",
      "[6440] g_loss: 6.852241516113281 - d_loss: 0.015540491789579391\n",
      "[6448] Saved checkpoint: log/ckpts/ckpt-208\n",
      "Epoch 208 completed.\n",
      "[6450] g_loss: 5.092309951782227 - d_loss: 0.04557560011744499\n",
      "[6460] g_loss: 7.405663013458252 - d_loss: 0.0011085583828389645\n",
      "[6470] g_loss: 4.917675018310547 - d_loss: 0.02981574274599552\n",
      "[6479] Saved checkpoint: log/ckpts/ckpt-209\n",
      "Epoch 209 completed.\n",
      "[6480] g_loss: 6.706229209899902 - d_loss: 0.005503457505255938\n",
      "[6490] g_loss: 4.3697004318237305 - d_loss: 0.03753019869327545\n",
      "[6500] g_loss: 4.934098720550537 - d_loss: 0.040252137929201126\n",
      "[6510] g_loss: 5.590989112854004 - d_loss: 0.01699930801987648\n",
      "[6510] Saved checkpoint: log/ckpts/ckpt-210\n",
      "Epoch 210 completed.\n",
      "[6520] g_loss: 4.826969146728516 - d_loss: 0.026301085948944092\n",
      "[6530] g_loss: 5.403911113739014 - d_loss: 0.026261664927005768\n",
      "[6540] g_loss: 5.424485683441162 - d_loss: 0.016167955473065376\n",
      "[6541] Saved checkpoint: log/ckpts/ckpt-211\n",
      "Epoch 211 completed.\n",
      "[6550] g_loss: 5.057883262634277 - d_loss: 0.02924075350165367\n",
      "[6560] g_loss: 8.561834335327148 - d_loss: 0.0021234527230262756\n",
      "[6570] g_loss: 5.016427993774414 - d_loss: 0.06544080376625061\n",
      "[6572] Saved checkpoint: log/ckpts/ckpt-212\n",
      "Epoch 212 completed.\n",
      "[6580] g_loss: 7.25741720199585 - d_loss: 0.028812788426876068\n",
      "[6590] g_loss: 6.538036346435547 - d_loss: 0.09544350206851959\n",
      "[6600] g_loss: 6.149003505706787 - d_loss: 0.014409445226192474\n",
      "[6603] Saved checkpoint: log/ckpts/ckpt-213\n",
      "Epoch 213 completed.\n",
      "[6610] g_loss: 5.578716278076172 - d_loss: 0.035759322345256805\n",
      "[6620] g_loss: 5.727445125579834 - d_loss: 0.025049937888979912\n",
      "[6630] g_loss: 6.458748817443848 - d_loss: 0.006754077505320311\n",
      "[6634] Saved checkpoint: log/ckpts/ckpt-214\n",
      "Epoch 214 completed.\n",
      "[6640] g_loss: 5.490118503570557 - d_loss: 0.014076340943574905\n",
      "[6650] g_loss: 4.008406162261963 - d_loss: 0.07519115507602692\n",
      "[6660] g_loss: 5.478494167327881 - d_loss: 0.03394368663430214\n",
      "[6665] Saved checkpoint: log/ckpts/ckpt-215\n",
      "Epoch 215 completed.\n",
      "[6670] g_loss: 8.393719673156738 - d_loss: 0.007357585243880749\n",
      "[6680] g_loss: 6.391390323638916 - d_loss: 0.02157071977853775\n",
      "[6690] g_loss: 5.775203704833984 - d_loss: 0.03302101790904999\n",
      "[6696] Saved checkpoint: log/ckpts/ckpt-216\n",
      "Epoch 216 completed.\n",
      "[6700] g_loss: 5.125062942504883 - d_loss: 0.025272943079471588\n",
      "[6710] g_loss: 4.8963727951049805 - d_loss: 0.015563378110527992\n",
      "[6720] g_loss: 6.876795768737793 - d_loss: 0.006671000272035599\n",
      "[6727] Saved checkpoint: log/ckpts/ckpt-217\n",
      "Epoch 217 completed.\n",
      "[6730] g_loss: 5.527740001678467 - d_loss: 0.02558090351521969\n",
      "[6740] g_loss: 4.469752311706543 - d_loss: 0.029259780421853065\n",
      "[6750] g_loss: 7.084468841552734 - d_loss: 0.003349161008372903\n",
      "[6758] Saved checkpoint: log/ckpts/ckpt-218\n",
      "Epoch 218 completed.\n",
      "[6760] g_loss: 8.956939697265625 - d_loss: 0.0512186735868454\n",
      "[6770] g_loss: 7.16819953918457 - d_loss: 0.0232708603143692\n",
      "[6780] g_loss: 9.389208793640137 - d_loss: 0.002547772601246834\n",
      "[6789] Saved checkpoint: log/ckpts/ckpt-219\n",
      "Epoch 219 completed.\n",
      "[6790] g_loss: 5.430680274963379 - d_loss: 0.019272571429610252\n",
      "[6800] g_loss: 10.107828140258789 - d_loss: 0.009285511448979378\n",
      "[6810] g_loss: 9.610574722290039 - d_loss: 0.009422671049833298\n",
      "[6820] g_loss: 7.170108318328857 - d_loss: 0.011412039399147034\n",
      "[6820] Saved checkpoint: log/ckpts/ckpt-220\n",
      "Epoch 220 completed.\n",
      "[6830] g_loss: 3.6543006896972656 - d_loss: 0.09330908954143524\n",
      "[6840] g_loss: 3.463798999786377 - d_loss: 0.03945975750684738\n",
      "[6850] g_loss: 3.3695573806762695 - d_loss: 0.11231236159801483\n",
      "[6851] Saved checkpoint: log/ckpts/ckpt-221\n",
      "Epoch 221 completed.\n",
      "[6860] g_loss: 8.011476516723633 - d_loss: 0.017725370824337006\n",
      "[6870] g_loss: 4.4277238845825195 - d_loss: 0.02944314479827881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6880] g_loss: 2.637939929962158 - d_loss: 0.17102864384651184\n",
      "[6882] Saved checkpoint: log/ckpts/ckpt-222\n",
      "Epoch 222 completed.\n",
      "[6890] g_loss: 8.331697463989258 - d_loss: 0.007991527207195759\n",
      "[6900] g_loss: 7.940680503845215 - d_loss: 0.006174752954393625\n",
      "[6910] g_loss: 7.997971057891846 - d_loss: 0.010777242481708527\n",
      "[6913] Saved checkpoint: log/ckpts/ckpt-223\n",
      "Epoch 223 completed.\n",
      "[6920] g_loss: 3.977123737335205 - d_loss: 0.037614502012729645\n",
      "[6930] g_loss: 14.198189735412598 - d_loss: 0.0004569671000353992\n",
      "[6940] g_loss: 5.598245143890381 - d_loss: 0.030772896483540535\n",
      "[6944] Saved checkpoint: log/ckpts/ckpt-224\n",
      "Epoch 224 completed.\n",
      "[6950] g_loss: 3.909323215484619 - d_loss: 0.11536019295454025\n",
      "[6960] g_loss: 6.955147743225098 - d_loss: 0.02812594175338745\n",
      "[6970] g_loss: 10.403316497802734 - d_loss: 0.03512096405029297\n",
      "[6975] Saved checkpoint: log/ckpts/ckpt-225\n",
      "Epoch 225 completed.\n",
      "[6980] g_loss: 10.794671058654785 - d_loss: 0.04833587631583214\n",
      "[6990] g_loss: 8.85223388671875 - d_loss: 0.004575448576360941\n",
      "[7000] g_loss: 5.05441951751709 - d_loss: 0.02332792431116104\n",
      "[7006] Saved checkpoint: log/ckpts/ckpt-226\n",
      "Epoch 226 completed.\n",
      "[7010] g_loss: 6.367569446563721 - d_loss: 0.040216490626335144\n",
      "[7020] g_loss: 5.430208206176758 - d_loss: 0.011048857122659683\n",
      "[7030] g_loss: 4.923216342926025 - d_loss: 0.014867013320326805\n",
      "[7037] Saved checkpoint: log/ckpts/ckpt-227\n",
      "Epoch 227 completed.\n",
      "[7040] g_loss: 5.134446620941162 - d_loss: 0.05002408102154732\n",
      "[7050] g_loss: 5.046392440795898 - d_loss: 0.010047167539596558\n",
      "[7060] g_loss: 7.000798225402832 - d_loss: 0.008676858618855476\n",
      "[7068] Saved checkpoint: log/ckpts/ckpt-228\n",
      "Epoch 228 completed.\n",
      "[7070] g_loss: 3.931411027908325 - d_loss: 0.06284204125404358\n",
      "[7080] g_loss: 3.140869617462158 - d_loss: 0.07190969586372375\n",
      "[7090] g_loss: 7.134494781494141 - d_loss: 0.007923195138573647\n",
      "[7099] Saved checkpoint: log/ckpts/ckpt-229\n",
      "Epoch 229 completed.\n",
      "[7100] g_loss: 3.5179479122161865 - d_loss: 0.03744529187679291\n",
      "[7110] g_loss: 6.336759567260742 - d_loss: 0.014782928861677647\n",
      "[7120] g_loss: 4.976258754730225 - d_loss: 0.04413335770368576\n",
      "[7130] g_loss: 4.1144514083862305 - d_loss: 0.09819445013999939\n",
      "[7130] Saved checkpoint: log/ckpts/ckpt-230\n",
      "Epoch 230 completed.\n",
      "[7140] g_loss: 1.5163240432739258 - d_loss: 0.4592929780483246\n",
      "[7150] g_loss: 7.64719295501709 - d_loss: 0.005905245430767536\n",
      "[7160] g_loss: 5.004700183868408 - d_loss: 0.03784744441509247\n",
      "[7161] Saved checkpoint: log/ckpts/ckpt-231\n",
      "Epoch 231 completed.\n",
      "[7170] g_loss: 8.572474479675293 - d_loss: 0.06443726271390915\n",
      "[7180] g_loss: 7.122821807861328 - d_loss: 0.04184471443295479\n",
      "[7190] g_loss: 4.320921897888184 - d_loss: 0.02549506351351738\n",
      "[7192] Saved checkpoint: log/ckpts/ckpt-232\n",
      "Epoch 232 completed.\n",
      "[7200] g_loss: 5.194483757019043 - d_loss: 0.015316672623157501\n",
      "[7210] g_loss: 6.203119277954102 - d_loss: 0.008348730392754078\n",
      "[7220] g_loss: 7.147653579711914 - d_loss: 0.026169423013925552\n",
      "[7223] Saved checkpoint: log/ckpts/ckpt-233\n",
      "Epoch 233 completed.\n",
      "[7230] g_loss: 5.05703592300415 - d_loss: 0.08983263373374939\n",
      "[7240] g_loss: 3.9157662391662598 - d_loss: 0.0692957267165184\n",
      "[7250] g_loss: 6.219300270080566 - d_loss: 0.006003297865390778\n",
      "[7254] Saved checkpoint: log/ckpts/ckpt-234\n",
      "Epoch 234 completed.\n",
      "[7260] g_loss: 6.191284656524658 - d_loss: 0.012720601633191109\n",
      "[7270] g_loss: 4.932450294494629 - d_loss: 0.03541136160492897\n",
      "[7280] g_loss: 9.612504959106445 - d_loss: 0.140959233045578\n",
      "[7285] Saved checkpoint: log/ckpts/ckpt-235\n",
      "Epoch 235 completed.\n",
      "[7290] g_loss: 8.493087768554688 - d_loss: 0.023676805198192596\n",
      "[7300] g_loss: 7.009454727172852 - d_loss: 0.13375848531723022\n",
      "[7310] g_loss: 7.023497104644775 - d_loss: 0.020063400268554688\n",
      "[7316] Saved checkpoint: log/ckpts/ckpt-236\n",
      "Epoch 236 completed.\n",
      "[7320] g_loss: 6.446870803833008 - d_loss: 0.01137192826718092\n",
      "[7330] g_loss: 6.7429728507995605 - d_loss: 0.061705611646175385\n",
      "[7340] g_loss: 6.022932052612305 - d_loss: 0.008349964395165443\n",
      "[7347] Saved checkpoint: log/ckpts/ckpt-237\n",
      "Epoch 237 completed.\n",
      "[7350] g_loss: 6.795472145080566 - d_loss: 0.006227987818419933\n",
      "[7360] g_loss: 5.354586601257324 - d_loss: 0.02810320444405079\n",
      "[7370] g_loss: 10.091748237609863 - d_loss: 0.10744428634643555\n",
      "[7378] Saved checkpoint: log/ckpts/ckpt-238\n",
      "Epoch 238 completed.\n",
      "[7380] g_loss: 11.170604705810547 - d_loss: 0.010980512946844101\n",
      "[7390] g_loss: 12.345478057861328 - d_loss: 0.04539722576737404\n",
      "[7400] g_loss: 8.891395568847656 - d_loss: 0.0039447094313800335\n",
      "[7409] Saved checkpoint: log/ckpts/ckpt-239\n",
      "Epoch 239 completed.\n",
      "[7410] g_loss: 8.860077857971191 - d_loss: 0.003211274975910783\n",
      "[7420] g_loss: 6.967260837554932 - d_loss: 0.01627662219107151\n",
      "[7430] g_loss: 9.990310668945312 - d_loss: 0.008167036809027195\n",
      "[7440] g_loss: 6.192718029022217 - d_loss: 0.01132513303309679\n",
      "[7440] Saved checkpoint: log/ckpts/ckpt-240\n",
      "Epoch 240 completed.\n",
      "[7450] g_loss: 6.505338668823242 - d_loss: 0.008975313976407051\n",
      "[7460] g_loss: 5.265334129333496 - d_loss: 0.012723652645945549\n",
      "[7470] g_loss: 7.69284200668335 - d_loss: 0.002222515642642975\n",
      "[7471] Saved checkpoint: log/ckpts/ckpt-241\n",
      "Epoch 241 completed.\n",
      "[7480] g_loss: 6.744614601135254 - d_loss: 0.028184041380882263\n",
      "[7490] g_loss: 7.519026756286621 - d_loss: 0.015482863411307335\n",
      "[7500] g_loss: 9.212697982788086 - d_loss: 0.18073290586471558\n",
      "[7502] Saved checkpoint: log/ckpts/ckpt-242\n",
      "Epoch 242 completed.\n",
      "[7510] g_loss: 11.130037307739258 - d_loss: 0.010591506958007812\n",
      "[7520] g_loss: 4.851096153259277 - d_loss: 0.03851280361413956\n",
      "[7530] g_loss: 7.447808265686035 - d_loss: 0.0048166303895413876\n",
      "[7533] Saved checkpoint: log/ckpts/ckpt-243\n",
      "Epoch 243 completed.\n",
      "[7540] g_loss: 3.7549827098846436 - d_loss: 0.06198979914188385\n",
      "[7550] g_loss: 7.578564167022705 - d_loss: 0.018982019275426865\n",
      "[7560] g_loss: 5.1708784103393555 - d_loss: 0.016193661838769913\n",
      "[7564] Saved checkpoint: log/ckpts/ckpt-244\n",
      "Epoch 244 completed.\n",
      "[7570] g_loss: 5.1189165115356445 - d_loss: 0.032726265490055084\n",
      "[7580] g_loss: 4.575685977935791 - d_loss: 0.03863654285669327\n",
      "[7590] g_loss: 6.512383460998535 - d_loss: 0.02561108022928238\n",
      "[7595] Saved checkpoint: log/ckpts/ckpt-245\n",
      "Epoch 245 completed.\n",
      "[7600] g_loss: 7.2064290046691895 - d_loss: 0.028296425938606262\n",
      "[7610] g_loss: 8.658578872680664 - d_loss: 0.3372240662574768\n",
      "[7620] g_loss: 4.190329074859619 - d_loss: 0.05842668563127518\n",
      "[7626] Saved checkpoint: log/ckpts/ckpt-246\n",
      "Epoch 246 completed.\n",
      "[7630] g_loss: 4.16442346572876 - d_loss: 0.06936879456043243\n",
      "[7640] g_loss: 10.673582077026367 - d_loss: 0.002937980927526951\n",
      "[7650] g_loss: 7.401532173156738 - d_loss: 0.007486996240913868\n",
      "[7657] Saved checkpoint: log/ckpts/ckpt-247\n",
      "Epoch 247 completed.\n",
      "[7660] g_loss: 6.692579746246338 - d_loss: 0.009970949962735176\n",
      "[7670] g_loss: 4.8438720703125 - d_loss: 0.01858418434858322\n",
      "[7680] g_loss: 6.59429931640625 - d_loss: 0.004227269906550646\n",
      "[7688] Saved checkpoint: log/ckpts/ckpt-248\n",
      "Epoch 248 completed.\n",
      "[7690] g_loss: 9.030176162719727 - d_loss: 0.0014544054865837097\n",
      "[7700] g_loss: 5.100734710693359 - d_loss: 0.05802977830171585\n",
      "[7710] g_loss: 5.415997505187988 - d_loss: 0.015703467652201653\n",
      "[7719] Saved checkpoint: log/ckpts/ckpt-249\n",
      "Epoch 249 completed.\n",
      "[7720] g_loss: 8.01343822479248 - d_loss: 0.023156028240919113\n",
      "[7730] g_loss: 5.993759632110596 - d_loss: 0.015112021006643772\n",
      "[7740] g_loss: 4.7785491943359375 - d_loss: 0.012989941984415054\n",
      "[7750] g_loss: 4.366899490356445 - d_loss: 0.05391557142138481\n",
      "[7750] Saved checkpoint: log/ckpts/ckpt-250\n",
      "Epoch 250 completed.\n",
      "[7760] g_loss: 6.18338680267334 - d_loss: 0.008424775674939156\n",
      "[7770] g_loss: 5.847322940826416 - d_loss: 0.04929099231958389\n",
      "[7780] g_loss: 4.797285079956055 - d_loss: 0.05286618322134018\n",
      "[7781] Saved checkpoint: log/ckpts/ckpt-251\n",
      "Epoch 251 completed.\n",
      "[7790] g_loss: 4.985528945922852 - d_loss: 0.02722761780023575\n",
      "[7800] g_loss: 6.159968376159668 - d_loss: 0.01086900569498539\n",
      "[7810] g_loss: 7.011919021606445 - d_loss: 0.008356122300028801\n",
      "[7812] Saved checkpoint: log/ckpts/ckpt-252\n",
      "Epoch 252 completed.\n",
      "[7820] g_loss: 5.810946464538574 - d_loss: 0.024028707295656204\n",
      "[7830] g_loss: 5.5253190994262695 - d_loss: 0.012854330241680145\n",
      "[7840] g_loss: 6.320205211639404 - d_loss: 0.009274648502469063\n",
      "[7843] Saved checkpoint: log/ckpts/ckpt-253\n",
      "Epoch 253 completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7850] g_loss: 6.478597640991211 - d_loss: 0.0036167888902127743\n",
      "[7860] g_loss: 5.468390941619873 - d_loss: 0.01150368433445692\n",
      "[7870] g_loss: 5.4288153648376465 - d_loss: 0.044104814529418945\n",
      "[7874] Saved checkpoint: log/ckpts/ckpt-254\n",
      "Epoch 254 completed.\n",
      "[7880] g_loss: 4.724697589874268 - d_loss: 0.02361968904733658\n",
      "[7890] g_loss: 6.754733085632324 - d_loss: 0.01517343521118164\n",
      "[7900] g_loss: 7.088025093078613 - d_loss: 0.01923716813325882\n",
      "[7905] Saved checkpoint: log/ckpts/ckpt-255\n",
      "Epoch 255 completed.\n",
      "[7910] g_loss: 5.847674369812012 - d_loss: 0.01624368131160736\n",
      "[7920] g_loss: 6.579262733459473 - d_loss: 0.00513227004557848\n",
      "[7930] g_loss: 6.988648891448975 - d_loss: 0.009359386749565601\n",
      "[7936] Saved checkpoint: log/ckpts/ckpt-256\n",
      "Epoch 256 completed.\n",
      "[7940] g_loss: 5.693020820617676 - d_loss: 0.019677959382534027\n",
      "[7950] g_loss: 5.416482925415039 - d_loss: 0.01931922137737274\n",
      "[7960] g_loss: 4.767340660095215 - d_loss: 0.017098788172006607\n",
      "[7967] Saved checkpoint: log/ckpts/ckpt-257\n",
      "Epoch 257 completed.\n",
      "[7970] g_loss: 4.056875705718994 - d_loss: 0.029488220810890198\n",
      "[7980] g_loss: 4.492562770843506 - d_loss: 0.10271134972572327\n",
      "[7990] g_loss: 7.6561079025268555 - d_loss: 0.0021432084031403065\n",
      "[7998] Saved checkpoint: log/ckpts/ckpt-258\n",
      "Epoch 258 completed.\n",
      "[8000] g_loss: 6.168134689331055 - d_loss: 0.004922204185277224\n",
      "[8010] g_loss: 4.905485153198242 - d_loss: 0.024031663313508034\n",
      "[8020] g_loss: 5.690289497375488 - d_loss: 0.012916707433760166\n",
      "[8029] Saved checkpoint: log/ckpts/ckpt-259\n",
      "Epoch 259 completed.\n",
      "[8030] g_loss: 5.889843940734863 - d_loss: 0.02017221972346306\n",
      "[8040] g_loss: 5.543763637542725 - d_loss: 0.013767139054834843\n",
      "[8050] g_loss: 10.556671142578125 - d_loss: 0.20109327137470245\n",
      "[8060] g_loss: 2.52919340133667 - d_loss: 0.13714264333248138\n",
      "[8060] Saved checkpoint: log/ckpts/ckpt-260\n",
      "Epoch 260 completed.\n",
      "[8070] g_loss: 10.642166137695312 - d_loss: 0.004713160917162895\n",
      "[8080] g_loss: 7.723129749298096 - d_loss: 0.004183189943432808\n",
      "[8090] g_loss: 12.223968505859375 - d_loss: 0.0005692422855645418\n",
      "[8091] Saved checkpoint: log/ckpts/ckpt-261\n",
      "Epoch 261 completed.\n",
      "[8100] g_loss: 12.170217514038086 - d_loss: 0.040427081286907196\n",
      "[8110] g_loss: 8.204123497009277 - d_loss: 0.016772214323282242\n",
      "[8120] g_loss: 7.977656364440918 - d_loss: 0.051668837666511536\n",
      "[8122] Saved checkpoint: log/ckpts/ckpt-262\n",
      "Epoch 262 completed.\n",
      "[8130] g_loss: 6.855810165405273 - d_loss: 0.004853677004575729\n",
      "[8140] g_loss: 4.438425540924072 - d_loss: 0.043690070509910583\n",
      "[8150] g_loss: 6.2766571044921875 - d_loss: 0.018610607832670212\n",
      "[8153] Saved checkpoint: log/ckpts/ckpt-263\n",
      "Epoch 263 completed.\n",
      "[8160] g_loss: 6.615180492401123 - d_loss: 0.03711465001106262\n",
      "[8170] g_loss: 4.887020111083984 - d_loss: 0.01898398995399475\n",
      "[8180] g_loss: 6.853511810302734 - d_loss: 0.003113784361630678\n",
      "[8184] Saved checkpoint: log/ckpts/ckpt-264\n",
      "Epoch 264 completed.\n",
      "[8190] g_loss: 8.874930381774902 - d_loss: 0.026979506015777588\n",
      "[8200] g_loss: 11.494863510131836 - d_loss: 0.023744629696011543\n",
      "[8210] g_loss: 8.254759788513184 - d_loss: 0.005453209392726421\n",
      "[8215] Saved checkpoint: log/ckpts/ckpt-265\n",
      "Epoch 265 completed.\n",
      "[8220] g_loss: 9.25365924835205 - d_loss: 0.026564205065369606\n",
      "[8230] g_loss: 7.393947601318359 - d_loss: 0.03176881745457649\n",
      "[8240] g_loss: 3.9023890495300293 - d_loss: 0.11230252683162689\n",
      "[8246] Saved checkpoint: log/ckpts/ckpt-266\n",
      "Epoch 266 completed.\n",
      "[8250] g_loss: 8.562013626098633 - d_loss: 0.029720114544034004\n",
      "[8260] g_loss: 5.7952494621276855 - d_loss: 0.009003449231386185\n",
      "[8270] g_loss: 4.279994964599609 - d_loss: 0.04740341007709503\n",
      "[8277] Saved checkpoint: log/ckpts/ckpt-267\n",
      "Epoch 267 completed.\n",
      "[8280] g_loss: 6.855159759521484 - d_loss: 0.005058069713413715\n",
      "[8290] g_loss: 6.146244525909424 - d_loss: 0.02834383212029934\n",
      "[8300] g_loss: 9.74228286743164 - d_loss: 0.015897788107395172\n",
      "[8308] Saved checkpoint: log/ckpts/ckpt-268\n",
      "Epoch 268 completed.\n",
      "[8310] g_loss: 10.137796401977539 - d_loss: 0.008415724150836468\n",
      "[8320] g_loss: 6.310995101928711 - d_loss: 0.005734435748308897\n",
      "[8330] g_loss: 6.289549827575684 - d_loss: 0.010685179382562637\n",
      "[8339] Saved checkpoint: log/ckpts/ckpt-269\n",
      "Epoch 269 completed.\n",
      "[8340] g_loss: 6.390415191650391 - d_loss: 0.008049936033785343\n",
      "[8350] g_loss: 6.407205581665039 - d_loss: 0.013532019220292568\n",
      "[8360] g_loss: 7.443416595458984 - d_loss: 0.05057041719555855\n",
      "[8370] g_loss: 6.29859733581543 - d_loss: 0.023575127124786377\n",
      "[8370] Saved checkpoint: log/ckpts/ckpt-270\n",
      "Epoch 270 completed.\n",
      "[8380] g_loss: 9.693771362304688 - d_loss: 0.027419809252023697\n",
      "[8390] g_loss: 7.611672401428223 - d_loss: 0.001400562236085534\n",
      "[8400] g_loss: 4.464263916015625 - d_loss: 0.02663569524884224\n",
      "[8401] Saved checkpoint: log/ckpts/ckpt-271\n",
      "Epoch 271 completed.\n",
      "[8410] g_loss: 3.2273340225219727 - d_loss: 0.10177649557590485\n",
      "[8420] g_loss: 8.813764572143555 - d_loss: 0.004234177991747856\n",
      "[8430] g_loss: 9.39930248260498 - d_loss: 0.0037394710816442966\n",
      "[8432] Saved checkpoint: log/ckpts/ckpt-272\n",
      "Epoch 272 completed.\n",
      "[8440] g_loss: 5.011549949645996 - d_loss: 0.03716464340686798\n",
      "[8450] g_loss: 6.187178134918213 - d_loss: 0.01752636581659317\n",
      "[8460] g_loss: 6.804202556610107 - d_loss: 0.014006162993609905\n",
      "[8463] Saved checkpoint: log/ckpts/ckpt-273\n",
      "Epoch 273 completed.\n",
      "[8470] g_loss: 3.096449136734009 - d_loss: 0.144802987575531\n",
      "[8480] g_loss: 3.7807435989379883 - d_loss: 0.0944836214184761\n",
      "[8490] g_loss: 9.707429885864258 - d_loss: 0.0008064571302384138\n",
      "[8494] Saved checkpoint: log/ckpts/ckpt-274\n",
      "Epoch 274 completed.\n",
      "[8500] g_loss: 6.475820541381836 - d_loss: 0.010700591839849949\n",
      "[8510] g_loss: 6.36342716217041 - d_loss: 0.06334874033927917\n",
      "[8520] g_loss: 7.297550201416016 - d_loss: 0.07667393982410431\n",
      "[8525] Saved checkpoint: log/ckpts/ckpt-275\n",
      "Epoch 275 completed.\n",
      "[8530] g_loss: 11.09825325012207 - d_loss: 0.004646008834242821\n",
      "[8540] g_loss: 5.99357795715332 - d_loss: 0.015234232880175114\n",
      "[8550] g_loss: 6.187098503112793 - d_loss: 0.02684643492102623\n",
      "[8556] Saved checkpoint: log/ckpts/ckpt-276\n",
      "Epoch 276 completed.\n",
      "[8560] g_loss: 10.424002647399902 - d_loss: 0.0446646586060524\n",
      "[8570] g_loss: 8.802730560302734 - d_loss: 0.0011702852789312601\n",
      "[8580] g_loss: 7.05674409866333 - d_loss: 0.03675168752670288\n",
      "[8587] Saved checkpoint: log/ckpts/ckpt-277\n",
      "Epoch 277 completed.\n",
      "[8590] g_loss: 5.033381938934326 - d_loss: 0.02532946690917015\n",
      "[8600] g_loss: 8.474143981933594 - d_loss: 0.02713642083108425\n",
      "[8610] g_loss: 7.636053085327148 - d_loss: 0.028654564172029495\n",
      "[8618] Saved checkpoint: log/ckpts/ckpt-278\n",
      "Epoch 278 completed.\n",
      "[8620] g_loss: 11.697066307067871 - d_loss: 0.004042250569909811\n",
      "[8630] g_loss: 5.404109954833984 - d_loss: 0.011725500226020813\n",
      "[8640] g_loss: 6.259296417236328 - d_loss: 0.004967977292835712\n",
      "[8649] Saved checkpoint: log/ckpts/ckpt-279\n",
      "Epoch 279 completed.\n",
      "[8650] g_loss: 5.716275215148926 - d_loss: 0.031373169273138046\n",
      "[8660] g_loss: 4.954278945922852 - d_loss: 0.035355012863874435\n",
      "[8670] g_loss: 7.126433849334717 - d_loss: 0.02479676343500614\n",
      "[8680] g_loss: 6.1178178787231445 - d_loss: 0.022506769746541977\n",
      "[8680] Saved checkpoint: log/ckpts/ckpt-280\n",
      "Epoch 280 completed.\n",
      "[8690] g_loss: 5.709641456604004 - d_loss: 0.009135089814662933\n",
      "[8700] g_loss: 7.752315998077393 - d_loss: 0.0086940573528409\n",
      "[8710] g_loss: 5.781703948974609 - d_loss: 0.036213114857673645\n",
      "[8711] Saved checkpoint: log/ckpts/ckpt-281\n",
      "Epoch 281 completed.\n",
      "[8720] g_loss: 7.2490553855896 - d_loss: 0.017820367589592934\n",
      "[8730] g_loss: 5.330718994140625 - d_loss: 0.018408184871077538\n",
      "[8740] g_loss: 5.228241920471191 - d_loss: 0.010341253131628036\n",
      "[8742] Saved checkpoint: log/ckpts/ckpt-282\n",
      "Epoch 282 completed.\n",
      "[8750] g_loss: 7.357893943786621 - d_loss: 0.004160490818321705\n",
      "[8760] g_loss: 8.013199806213379 - d_loss: 0.01071915216743946\n",
      "[8770] g_loss: 6.758878707885742 - d_loss: 0.02055881731212139\n",
      "[8773] Saved checkpoint: log/ckpts/ckpt-283\n",
      "Epoch 283 completed.\n",
      "[8780] g_loss: 6.887334823608398 - d_loss: 0.02531502954661846\n",
      "[8790] g_loss: 8.368587493896484 - d_loss: 0.010993672534823418\n",
      "[8800] g_loss: 6.139225006103516 - d_loss: 0.007165658287703991\n",
      "[8804] Saved checkpoint: log/ckpts/ckpt-284\n",
      "Epoch 284 completed.\n",
      "[8810] g_loss: 9.998069763183594 - d_loss: 0.06307568401098251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8820] g_loss: 9.410928726196289 - d_loss: 0.002459548646584153\n",
      "[8830] g_loss: 6.842190742492676 - d_loss: 0.01163228414952755\n",
      "[8835] Saved checkpoint: log/ckpts/ckpt-285\n",
      "Epoch 285 completed.\n",
      "[8840] g_loss: 7.600561141967773 - d_loss: 0.0023116362281143665\n",
      "[8850] g_loss: 8.2756929397583 - d_loss: 0.014357846230268478\n",
      "[8860] g_loss: 8.613699913024902 - d_loss: 0.002700233133509755\n",
      "[8866] Saved checkpoint: log/ckpts/ckpt-286\n",
      "Epoch 286 completed.\n",
      "[8870] g_loss: 5.505533218383789 - d_loss: 0.02954746037721634\n",
      "[8880] g_loss: 4.5686421394348145 - d_loss: 0.09842093288898468\n",
      "[8890] g_loss: 9.45881462097168 - d_loss: 0.0012989076785743237\n",
      "[8897] Saved checkpoint: log/ckpts/ckpt-287\n",
      "Epoch 287 completed.\n",
      "[8900] g_loss: 7.530735015869141 - d_loss: 0.02875472418963909\n",
      "[8910] g_loss: 11.174363136291504 - d_loss: 0.03464796021580696\n",
      "[8920] g_loss: 8.530645370483398 - d_loss: 0.002030392875894904\n",
      "[8928] Saved checkpoint: log/ckpts/ckpt-288\n",
      "Epoch 288 completed.\n",
      "[8930] g_loss: 6.105060577392578 - d_loss: 0.009999166242778301\n",
      "[8940] g_loss: 5.689461708068848 - d_loss: 0.025558240711688995\n",
      "[8950] g_loss: 5.29840087890625 - d_loss: 0.03895217180252075\n",
      "[8959] Saved checkpoint: log/ckpts/ckpt-289\n",
      "Epoch 289 completed.\n",
      "[8960] g_loss: 9.46237564086914 - d_loss: 0.010031606070697308\n",
      "[8970] g_loss: 7.673977851867676 - d_loss: 0.06104588136076927\n",
      "[8980] g_loss: 7.378662109375 - d_loss: 0.09680311381816864\n",
      "[8990] g_loss: 5.612607955932617 - d_loss: 0.0227031446993351\n",
      "[8990] Saved checkpoint: log/ckpts/ckpt-290\n",
      "Epoch 290 completed.\n",
      "[9000] g_loss: 7.587320327758789 - d_loss: 0.007436887826770544\n",
      "[9010] g_loss: 9.521007537841797 - d_loss: 0.009096495807170868\n",
      "[9020] g_loss: 5.302244663238525 - d_loss: 0.023359622806310654\n",
      "[9021] Saved checkpoint: log/ckpts/ckpt-291\n",
      "Epoch 291 completed.\n",
      "[9030] g_loss: 8.184881210327148 - d_loss: 0.02138679102063179\n",
      "[9040] g_loss: 3.7288618087768555 - d_loss: 0.06328077614307404\n",
      "[9050] g_loss: 5.062705993652344 - d_loss: 0.028425518423318863\n",
      "[9052] Saved checkpoint: log/ckpts/ckpt-292\n",
      "Epoch 292 completed.\n",
      "[9060] g_loss: 8.374042510986328 - d_loss: 0.007720013149082661\n",
      "[9070] g_loss: 8.683380126953125 - d_loss: 0.11593397706747055\n",
      "[9080] g_loss: 12.250396728515625 - d_loss: 0.007505039684474468\n",
      "[9083] Saved checkpoint: log/ckpts/ckpt-293\n",
      "Epoch 293 completed.\n",
      "[9090] g_loss: 9.987483978271484 - d_loss: 0.02032930962741375\n",
      "[9100] g_loss: 4.425800323486328 - d_loss: 0.08023732155561447\n",
      "[9110] g_loss: 7.211190223693848 - d_loss: 0.002858723048120737\n",
      "[9114] Saved checkpoint: log/ckpts/ckpt-294\n",
      "Epoch 294 completed.\n",
      "[9120] g_loss: 5.806282043457031 - d_loss: 0.006740580778568983\n",
      "[9130] g_loss: 4.949326038360596 - d_loss: 0.027437672019004822\n",
      "[9140] g_loss: 3.6737232208251953 - d_loss: 0.09874527156352997\n",
      "[9145] Saved checkpoint: log/ckpts/ckpt-295\n",
      "Epoch 295 completed.\n",
      "[9150] g_loss: 9.529657363891602 - d_loss: 0.0037236670032143593\n",
      "[9160] g_loss: 2.702643394470215 - d_loss: 0.5897305607795715\n",
      "[9170] g_loss: 7.998163223266602 - d_loss: 0.15314798057079315\n",
      "[9176] Saved checkpoint: log/ckpts/ckpt-296\n",
      "Epoch 296 completed.\n",
      "[9180] g_loss: 7.650471210479736 - d_loss: 0.04257907718420029\n",
      "[9190] g_loss: 8.204516410827637 - d_loss: 0.003996196668595076\n",
      "[9200] g_loss: 10.209881782531738 - d_loss: 0.029699046164751053\n",
      "[9207] Saved checkpoint: log/ckpts/ckpt-297\n",
      "Epoch 297 completed.\n",
      "[9210] g_loss: 11.0294189453125 - d_loss: 0.058943748474121094\n",
      "[9220] g_loss: 10.455442428588867 - d_loss: 0.022002439945936203\n",
      "[9230] g_loss: 4.821620941162109 - d_loss: 0.11810418963432312\n",
      "[9238] Saved checkpoint: log/ckpts/ckpt-298\n",
      "Epoch 298 completed.\n",
      "[9240] g_loss: 8.670642852783203 - d_loss: 0.03107570670545101\n",
      "[9250] g_loss: 13.358558654785156 - d_loss: 0.020725145936012268\n",
      "[9260] g_loss: 7.965483665466309 - d_loss: 0.004731276538223028\n",
      "[9269] Saved checkpoint: log/ckpts/ckpt-299\n",
      "Epoch 299 completed.\n",
      "[9270] g_loss: 7.612432956695557 - d_loss: 0.004431231878697872\n",
      "[9280] g_loss: 7.106481075286865 - d_loss: 0.007405170239508152\n",
      "[9290] g_loss: 5.715028762817383 - d_loss: 0.02046428620815277\n",
      "[9300] g_loss: 5.907279968261719 - d_loss: 0.014664163812994957\n",
      "[9300] Saved checkpoint: log/ckpts/ckpt-300\n",
      "Epoch 300 completed.\n"
     ]
    }
   ],
   "source": [
    "from ashpy.trainers.gan import AdversarialTrainer\n",
    "\n",
    "epochs = 300\n",
    "logdir = \"log\"\n",
    "metrics = []\n",
    "\n",
    "trainer = AdversarialTrainer(\n",
    "    generator=G,\n",
    "    discriminator=D,\n",
    "    generator_optimizer=tf.optimizers.Adam(1e-4),\n",
    "    discriminator_optimizer=tf.optimizers.Adam(1e-4),\n",
    "    generator_loss=generator_bce,\n",
    "    discriminator_loss=minmax,\n",
    "    epochs=epochs,\n",
    "    metrics=metrics,\n",
    "    logdir=logdir,\n",
    ")\n",
    "\n",
    "trainer(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Towards Serving\n",
    "\n",
    "The path to the production is straightforward. We only have to save the model parameters and export them as a graph.\n",
    "Begin our generator a Keras model, saving it to the disk is as easy as calling the `save_weights` method in the Generator model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.save_weights('generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Links\n",
    "\n",
    "<a id=\"1\">[1]</a>: Generative Adversarial Networks : https://arxiv.org/abs/1406.2661\n",
    "\n",
    "<a id=\"2\">[2]</a>: really-awesome-gan : https://github.com/nightrome/really-awesome-gan\n",
    "\n",
    "<a id=\"3\">[3]</a>: DCGAN : https://arxiv.org/abs/1511.06434\n",
    "\n",
    "<a id=\"4\">[4]</a>: Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift : https://arxiv.org/abs/1502.03167\n",
    "\n",
    "<a id=\"5\">[5]</a>: How Does Batch Normalization Help Optimization? : https://arxiv.org/abs/1805.11604"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "204.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
